<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"willzhuang.github.io","root":"/","images":"/images","scheme":"Muse","version":"8.3.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="1. 背景BloombergGPT是布隆伯格2023年3月30日公开在arXiv的一篇文章——BloombergGPT: A Large Language Model for Finance中涉及到的语言模型，也是金融领域第一个公开发表文章的大语言模型（以下简称“LLM”）。 2. 要点 BloombergGPT是Bloomberg训练出来的金融大语言模型（LLM for Finance） 模型参">
<meta property="og:type" content="article">
<meta property="og:title" content="BloombergGPT论文解读">
<meta property="og:url" content="https://willzhuang.github.io/2023/09/14/BloombergGPT%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/index.html">
<meta property="og:site_name" content="Zhuang&#39;s Diary">
<meta property="og:description" content="1. 背景BloombergGPT是布隆伯格2023年3月30日公开在arXiv的一篇文章——BloombergGPT: A Large Language Model for Finance中涉及到的语言模型，也是金融领域第一个公开发表文章的大语言模型（以下简称“LLM”）。 2. 要点 BloombergGPT是Bloomberg训练出来的金融大语言模型（LLM for Finance） 模型参">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-09-14T08:31:00.000Z">
<meta property="article:modified_time" content="2023-09-14T09:13:31.077Z">
<meta property="article:author" content="Weiming Zhuang">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://willzhuang.github.io/2023/09/14/BloombergGPT%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>BloombergGPT论文解读 | Zhuang's Diary</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhuang's Diary</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">言之有物，持之以恒</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E8%83%8C%E6%99%AF"><span class="nav-number">1.</span> <span class="nav-text">1. 背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E8%A6%81%E7%82%B9"><span class="nav-number">2.</span> <span class="nav-text">2. 要点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">3.</span> <span class="nav-text">3.数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%87%91%E8%9E%8D%E9%A2%86%E5%9F%9F%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">3.1.</span> <span class="nav-text">金融领域数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%9A%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">3.2.</span> <span class="nav-text">通用数据集</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.</span> <span class="nav-text">4.模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">4.1.</span> <span class="nav-text">模型结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%B0%BA%E5%BA%A6"><span class="nav-number">4.2.</span> <span class="nav-text">模型尺度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E9%85%8D%E7%BD%AE"><span class="nav-number">4.3.</span> <span class="nav-text">训练配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%BC%98%E5%8C%96%E9%87%87%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95"><span class="nav-number">4.4.</span> <span class="nav-text">大规模优化采用的方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="nav-number">5.</span> <span class="nav-text">训练过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E8%AF%84%E4%BC%B0"><span class="nav-number">6.</span> <span class="nav-text">5.评估</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#holdout-loss"><span class="nav-number">6.1.</span> <span class="nav-text">holdout loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%96%E9%83%A8%E4%BB%BB%E5%8A%A1"><span class="nav-number">6.2.</span> <span class="nav-text">外部任务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Bloomberg%E5%86%85%E9%83%A8%E4%BB%BB%E5%8A%A1%E4%B9%8B%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90"><span class="nav-number">6.3.</span> <span class="nav-text">Bloomberg内部任务之情感分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%A2%E7%B4%A2%E6%80%A7%E4%BB%BB%E5%8A%A1%EF%BC%9ANER"><span class="nav-number">6.4.</span> <span class="nav-text">探索性任务：NER</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%9A%E7%94%A8%E4%BB%BB%E5%8A%A1"><span class="nav-number">6.5.</span> <span class="nav-text">通用任务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%84%E6%B5%8B%E6%80%BB%E7%BB%93"><span class="nav-number">6.6.</span> <span class="nav-text">评测总结</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9A%E6%80%A7%E8%AF%84%E4%BC%B0"><span class="nav-number">6.7.</span> <span class="nav-text">定性评估</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-%E9%81%93%E5%BE%B7%E4%BC%A6%E7%90%86%E3%80%81%E9%99%90%E5%88%B6%E4%B8%8E%E7%A0%94%E7%A9%B6%E6%84%8F%E4%B9%89"><span class="nav-number">7.</span> <span class="nav-text">6.道德伦理、限制与研究意义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B"><span class="nav-number">8.</span> <span class="nav-text">7.总结与展望</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Weiming Zhuang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">240</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">60</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/zhuangweiming/" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhuangweiming&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://willzhuang.github.io/2023/09/14/BloombergGPT%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          BloombergGPT论文解读
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-09-14 16:31:00 / Modified: 17:13:31" itemprop="dateCreated datePublished" datetime="2023-09-14T16:31:00+08:00">2023-09-14</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h3><p>BloombergGPT是布隆伯格2023年3月30日公开在arXiv的一篇文章——<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.17564">BloombergGPT: A Large Language Model for Finance</a>中涉及到的语言模型，也是金融领域第一个公开发表文章的大语言模型（以下简称“LLM”）。</p>
<h3 id="2-要点"><a href="#2-要点" class="headerlink" title="2. 要点"></a>2. 要点</h3><ul>
<li>BloombergGPT是Bloomberg训练出来的金融大语言模型（LLM for Finance）</li>
<li>模型参数量为500亿，使用了包含3630亿token的金融领域数据集以及3450亿token的通用数据集</li>
<li>隐藏层维度为7680，多头的头数为40</li>
<li>模型采用Unigram tokenizer，AdamW优化器</li>
<li>模型在64个AWS的p4d.24xlarge实例上训练了53天，其中每个p4d.24xlarge实例包含了8块40GB的A100GPU</li>
<li>对BloombergGPT的评估包含了两部分：金融领域评估与通用领域评估</li>
<li>评估对比的其他大语言模型有GPT-NeoX、OPT、BLOOM、GPT-3</li>
<li>在金融领域任务上，BloombergGPT综合表现最好；在通用任务上，BloombergGPT的综合得分同样优于相同参数量级的其他模型，并且在某些任务上的得分要高于参数量更大的模型</li>
<li>BloombergGPT模型在金融领域取得好效果的同时，并没有以牺牲模型通用能力为代价</li>
<li>对模型定性评估的结果表明，BloombergGPT可以提高工作效率</li>
<li>出于安全性的考虑，BloogbergGPT模型不会被公开，但是模型训练和评估的相关经验和思考会被分享出来</li>
<li>作者认为，对模型效果提升促进最大的三个因素（按影响从高到低排序）分别为精心清洗的数据集、合理的tokenizer、流行的模型结构</li>
</ul>
<p>文章的主要贡献在以下几点：</p>
<ul>
<li>混合数据集训练方法不仅可以在特定任务上表现出色，也可以在一般NLP基准测试上表现良好</li>
<li>不同于常见的网络爬取数据，本文的数据包含了巨量的可信来源的精心清洗的数据</li>
<li>不仅包含了模型在基准测试集上的评估结果，也包含了在Bloomberg内部任务上的评估结果</li>
<li>在超过7000亿个token的语料库中的5690亿个token上训练出一个500亿参数的LLM</li>
<li>使用Unigram模型而非常用的基于贪心合并的子词标记器进行tokenize，方便在推理时进行更智能的标记化</li>
<li>借鉴BLOOM的训练大模型方法，同时也将自己自己在训练BloombergGPT中的经验分享</li>
</ul>
<h3 id="3-数据集"><a href="#3-数据集" class="headerlink" title="3.数据集"></a>3.数据集</h3><p><strong>BloombergGPT是一个有500亿参数、基于BLOOM模型的LLM</strong>，过程中采用了一种兼具通用能力和特定领域的方法。<br>作者首先构建了FinPile——一个包含了新闻、档案、网络爬取的新闻稿件、英文财经文档等英文金融文档的金融领域数据集，同时也采用了通用的数据集。</p>
<h4 id="金融领域数据集"><a href="#金融领域数据集" class="headerlink" title="金融领域数据集"></a>金融领域数据集</h4><p>金融领域数据集共包含了3630亿个token，占总数据集token量的54.2%，具体由以下几个部分构成：</p>
<ul>
<li>金融领域相关网页，2980亿token，占比42.01%</li>
<li>金融领域知名新闻源，380亿token，占比5.31%</li>
<li>公司财报，140亿token，占比2.04%</li>
<li>金融相关公司的出版物，90亿token，占比1.21%</li>
<li>bloomberg，50亿token，占比0.7%</li>
</ul>
<p>因为包含一部分收费和私有数据，所以这份数据集不会被公开，但是文章中公开了模型训练方法。</p>
<h4 id="通用数据集"><a href="#通用数据集" class="headerlink" title="通用数据集"></a>通用数据集</h4><p>**通用数据集共包含了3450亿个token，占总数据集token量的48.73%**，具体分为如下几个部分：</p>
<ul>
<li>The Pile数据集，1840亿token，占比25.9%</li>
<li>C4数据集，1380亿token，占比19.48%</li>
<li>Wikipedia数据集，240亿token，占比3.35%</li>
</ul>
<p>数据集使用Unigram tokenizer对原始文本进行tokenize。具体处理时，作者这了两点改进（具体内容可参考原论文《2.3Tokenization》）：</p>
<ul>
<li>在pretokenization这一步，将数字视为单个token，并且允许词组的存在，以提高信息密度减少句子长度</li>
<li>使用分治的思想优化Unigram tokenizer在大数据集上的实现，并对最终词表大小控制在13万这个数量级上</li>
</ul>
<h3 id="4-模型"><a href="#4-模型" class="headerlink" title="4.模型"></a>4.模型</h3><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>模型基于BLOOM模型的自回归结构，具体包含了70层transformer decoder。<br>另外一些细节如下（详见《3.1 Architecture》）：</p>
<ul>
<li>前馈层（FFN）中的非线性函数采用GELU</li>
<li>位置编码采用ALiBi编码</li>
<li>模型在第一层多了一个layer normalization</li>
</ul>
<h4 id="模型尺度"><a href="#模型尺度" class="headerlink" title="模型尺度"></a>模型尺度</h4><p>这一部分，作者先有了算力预算（<strong>40G内存A100共130万GPU小时</strong>），并且给中间checkpoint存储留出了约25%的时间预算。<br><strong>根据Chinchilla scaling laws，计算出模型的参数和需要的数据量大小——模型参数为500亿，token数据量为11000+亿</strong>。<br>考虑到金融领域token数量要占总token数量的50%以上，而且目前的数据暂时无法再进行扩充，最终<strong>模型参数量选择为500亿，token数据量为7000+亿</strong>。<br>另一方面，隐藏层维度D也可以根据decoder的层数计算出来，这里经过计算<strong>隐藏层维度为7680</strong>，多头的<strong>头数为40</strong>。</p>
<h4 id="训练配置"><a href="#训练配置" class="headerlink" title="训练配置"></a>训练配置</h4><p>这一部分原始论文写的比较详细，具体见《3.3 Training Configuration》，这里简单摘要如下：</p>
<ul>
<li>作者在<strong>每篇文档的最后添加了特殊标记&lt;|endoftext|&gt;，模型训练时选取的句子长度为2048token</strong></li>
<li>训练时采用的优化方法是<strong>AdamW，beta1、beta2、weight decay取值分别为0.9、0.95、0.1</strong>，初始学习率为6e-5，采用cosine衰减、线性warmup方式</li>
<li>模型参数随机初始化为<strong>均值0、标准差0.006588的正态分布</strong>，并对MLP的第二层和注意力层输出进行缩放</li>
<li>关于训练的不稳定性，文章中没有描述训练BloombergGPT时采用的方法，只是介绍了相关进展</li>
<li>关于计算使用到的硬件，使用了<strong>64个AWS的p4d.24xlarge实例，每个p4d.24xlarge实例包含了8块40GB的A100GPU</strong></li>
</ul>
<h4 id="大规模优化采用的方法"><a href="#大规模优化采用的方法" class="headerlink" title="大规模优化采用的方法"></a>大规模优化采用的方法</h4><p>这一部分中，作者描述了具体优化时采用的方法：ZeRO优化、MiCS、Activation Checkpointing、混合精度训练（Mixed Precision Training）、内核融合（fused kernels）。<br>具体见《3.4 Large-scale Optimization》<br>经过上述优化，上述硬件的<strong>平均算力水平达到了102TFLOPs</strong>，<strong>训练一步需要32.5秒</strong>。</p>
<h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><p>文章中记录<strong>模型共训练了139,200步</strong>，进行了约<strong>0.8个epoch</strong>，<strong>训练了53天</strong>。<br>一个epoch都没有训练完的原因是这时验证集上的损失函数已经不再继续下降了。<br><strong>具体训练过程如下</strong>：</p>
<ul>
<li>初始训练的batch size大小为1024，warm-up过程持续了7200步，随后作者将batch size修改为2048。</li>
<li>115,500步之后，验证集上的损失不再下降，然后作者将学习率缩小为原始的2/3；</li>
<li>129,900步之后，学习率缩小为之前的1/2，同时增加dropout</li>
<li>137,100步之后，学习率再次缩小为之前的1/2</li>
<li>最终，训练在146,000步结束。作者选取139,200这一步的模型最为最终使用的模型</li>
</ul>
<p>这里推荐阅读原始文章3.3节与3.4节中关于训练方法的描述，对于大模型训练有一定的参考意义。</p>
<h3 id="5-评估"><a href="#5-评估" class="headerlink" title="5.评估"></a>5.评估</h3><p>文章中对BloombergGPT的<strong>评估分成了两部分</strong>：<strong>金融领域任务与通用任务</strong>。这样做的目的也比较直观，就是<strong>验证在特定领域预训练后的模型能够在特定领域表现好，同时在通用领域的表现也不会差太多</strong>这一观点。<br>同时，文章<strong>对比了BloombergGPT、GPT-NeoX、OPT、BLOOM、GPT-3在不同任务上的表现</strong>。注意，这里<strong>因为GPT-3模型无法获取，故仅在部分通用任务上进行了评测</strong>。<br>作者对每一个模型均独立进行了评测，并且在每一个任务中使用相同的标准prompt、相同的样例、不使用任务描述和任何CoT prompt，以保证评测结果的公平性。<br>对于有多个答案的任务，文章中采用了**基于似然的分类方法（likelihood-based classification）进行评估；对于其他任务，文章采用贪心解码（greedy decoding）的方式进行评估。</p>
<h4 id="holdout-loss"><a href="#holdout-loss" class="headerlink" title="holdout loss"></a>holdout loss</h4><p>作者首先在FinPile数据集预留的部分样本上对各个模型进行了bits per byte的评估。<br>bits per byte指标是评估语言模型的一种常见指标<strong>，类似于perplexity，取值越小，模型越好。具体计算方法可见</strong><a target="_blank" rel="noopener" href="https://stats.stackexchange.com/a/261789">How to compute bits per character (BPC)?</a><br><strong>BloombergGPT在金融语料上的bits per byte均好于其他模型，并且在财报（Filings）这个类别上表现尤其突出</strong>。这个结果也符合预期。否则可能就没有后面任务对比的必要了。<br>文章又将金融领域任务分成了<strong>外部任务和Bloomberg内部任务</strong>。在每个任务上，作者除了评估模型在任务上的表现，还评估了同一任务下不同模型生成结果之间两两比较的胜率（WR）。</p>
<h4 id="外部任务"><a href="#外部任务" class="headerlink" title="外部任务"></a>外部任务</h4><p>外部任务主要如下：</p>
<ul>
<li>ConvFinQA，标普500收益报告问答推理</li>
<li>FiQA SA，金融新闻和微博客标题基于方面的情感三分类（正负中）</li>
<li>FPB，金融新闻句子级别情感三分类（正负中）</li>
<li>Headline，新闻标题在预定义标签下的二分类</li>
<li>NER，信用风险评估数据的命名实体识别</li>
</ul>
<p><strong>BloombergGPT在上述5个任务中的4个都取得了最好效果，在另外一个取得了第二名；并且在模型两两结果对比的胜率最高，同时在ConvFinQA这个任务上遥遥领先。</strong></p>
<h4 id="Bloomberg内部任务之情感分析"><a href="#Bloomberg内部任务之情感分析" class="headerlink" title="Bloomberg内部任务之情感分析"></a>Bloomberg内部任务之情感分析</h4><p>这个任务中的情感分析均为基于方面的情感三分类（aspect-specific sentiment），数据集的内容通过任务名称就可以略知一二。<br><strong>BloombergGPT在上述4个数据集上的表现均大幅领先于其他模型</strong>。</p>
<h4 id="探索性任务：NER"><a href="#探索性任务：NER" class="headerlink" title="探索性任务：NER"></a>探索性任务：NER</h4><p>注意，这里的<strong>NER只涉及到ORG、PER、LOC这三类实体</strong>。<br>同时探索性任务<strong>NER+NED是指识别出实体后再将实体链接到上市公司的股票简称</strong>。比如“AAPL announced that they will stop using Intel chips in future products.” 这句话<strong>NER的结果是“AAPL, Intel”</strong>，<strong>NER+NED的结果是 “AAPL, INTC”</strong>。<br>这两类任务涉及到的数据集包括了<strong>7个数据集</strong>，分别为BN（Bloomberg BN wire上内容）、BFW（Bloomberg First Word上的内容）、Filings（财报内容）、Headlines（Bloomberg news内容）、Premium（Bloogberg收录 的第三方新闻内容）、Transcripts（公司新闻发布会的文字记录）、Social Media。<br>最终，<strong>NER任务下，BloombergGPT仅在Headlines这一个数据集上得分最高；但在NER+NED任务下，BloombergGPT在除了Social Media任务的其他任务上均得分第一</strong>。</p>
<h4 id="通用任务"><a href="#通用任务" class="headerlink" title="通用任务"></a>通用任务</h4><p>文章在通用任务上做了相当多的对比，这里<strong>仅对任务类型和结果做简要描述，详细内容见文章中的5.4~5.7节</strong>。<br>作者在<strong>BIG-bench Hard</strong>（BIG-bench的一个子集，仅包含目前模型表现无法超过人类的任务）、<strong>常识测试</strong>（不提供任何背景知识，仅可以训练时使用的数据）、<strong>阅读理解</strong>、<strong>语言学</strong>（消歧、语法识别、蕴含判别等）等任务上进行了测试。<br><strong>在BIG-bench Hard任务上，BloombergGPT得分低于参数量更大的PaLM和BLOOM，但是与参数规模类似的GPT-NeoX或OPT66B相比，BloombergGPT的性能更接近BLOOM</strong>，这说明开发金融专用的大语言模型并没有明显牺牲其通用能力。<br><strong>在常识测试任务中，BloombergGPT在1个任务上取得了第一名，在其余3个任务上取得了第二名（这里未考虑GPT-3）</strong>。<br><strong>在阅读理解任务上，GPT-3在所有任务上排名第一，BloombergGPT在5/6个任务上排名第二</strong>，且得分远高于BLOOM模型。<br><strong>在语言学任务上，GPT-3在综合排名第一，BloombergGPT综合排名第二</strong>，且综合得分高于BLOOM模型。</p>
<h4 id="评测总结"><a href="#评测总结" class="headerlink" title="评测总结"></a>评测总结</h4><p><strong>在金融领域任务上，BloombergGPT综合表现最好</strong>；<br><strong>在通用任务上，BloombergGPT的综合得分优于相同参数量级的其他模型，并且在某些任务上的得分要高于参数量更大的模型</strong>。<br>这都说明，开发金融专用的大语言模型在金融领域取得好效果的同时，并没有以牺牲模型通用能力为代价。<br>这一结论也可以给我们一个启示，<strong>在其他特定领域，我们也可以开发专用的大语言模型</strong>。</p>
<h4 id="定性评估"><a href="#定性评估" class="headerlink" title="定性评估"></a>定性评估</h4><p>作者在文章的第6章还展示了对BloombergGPT定性评估的例子，以展示模型在专业领域带来的促进作用。<br>这些列子包括：</p>
<ul>
<li>BQL（Bloomberg查询语言）生成，即使用自然语言完成Bloomberg数据库查询，类似NL2SQL</li>
<li>新闻标题提示，辅助记者生成新闻短标题</li>
<li>金融问答</li>
</ul>
<h3 id="6-道德伦理、限制与研究意义"><a href="#6-道德伦理、限制与研究意义" class="headerlink" title="6.道德伦理、限制与研究意义"></a>6.道德伦理、限制与研究意义</h3><p>这一章没有太多值得写的，主要就是强调了目前大语言模型可能会生成有害的、有偏见的内容，并且可能存在prompt注入导致信息泄露的风险，Bloomberg在使用大语言模型前后都会做好风控，保证生成内容的准确性。<br>同时，<strong>BloogbergGPT模型不会被公开，但是模型训练和评估的相关经验和思考会被分享出来</strong>。</p>
<h3 id="7-总结与展望"><a href="#7-总结与展望" class="headerlink" title="7.总结与展望"></a>7.总结与展望</h3><p>文章提出了BloombergGPT——一个金融领域顶级的LLM，并且在训练特定领域大语言模型做出了如下贡献：</p>
<ul>
<li><strong>使用领域数据和通用数据的训练方式可以让模型在这两个方面得到平衡的结果</strong></li>
<li>模型参数量参考了Chinchilla scaling laws</li>
<li>公布了相关训练细节</li>
</ul>
<p>下一步，作者们会在以下方向继续研究：</p>
<ul>
<li>金融领域的fine-tuning</li>
<li>使用更无害和更无偏见的语言</li>
<li>研究tokenization方法对模型结果的影响</li>
</ul>
<p>最后，作者把模型取得目前效果归结于以下三个因素（按影响从高到低排序）：</p>
<ul>
<li><strong>精心清洗的内部数据集</strong></li>
<li><strong>tokenizer的选择</strong></li>
<li><strong>流行的模型结构</strong></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Weiming Zhuang
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://willzhuang.github.io/2023/09/14/BloombergGPT%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="BloombergGPT论文解读">https://willzhuang.github.io/2023/09/14/BloombergGPT论文解读/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/09/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B/" rel="prev" title="深度学习推荐模型">
                  <i class="fa fa-chevron-left"></i> 深度学习推荐模型
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/09/18/%E5%B9%82%E7%AD%89%E6%80%A7%E6%9C%8D%E5%8A%A1/" rel="next" title="幂等性服务">
                  幂等性服务 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Weiming Zhuang</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'none'
      },
      options: {
        renderActions: {
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css">

<script>
NexT.utils.loadComments('.gitalk-container', () => {
  NexT.utils.getScript('https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'bcfbeadd6147f39af62f',
      clientSecret: '36f4ca5368918536f72f6b3816b90c30f61effb3',
      repo        : 'willzhuang.github.io',
      owner       : 'WillZhuang',
      admin       : ['WillZhuang'],
      id          : '0b838ec0024d87aa41e303865d7b38b8',
      proxy       : 'https://cors-anywhere.herokuapp.com/https://github.com/login/oauth/access_token',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render(document.querySelector('.gitalk-container'));
  }, window.Gitalk);
});
</script>

</body>
</html>
