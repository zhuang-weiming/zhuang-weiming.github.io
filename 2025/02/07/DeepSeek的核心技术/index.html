<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhuang-weiming.github.io","root":"/","images":"/images","scheme":"Muse","version":"8.3.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="一、关于DeepSeek公司及其大模型1.1 公司概况DeepSeek 2023年7月成立于杭州，是幻方量化旗下的子公司，全称是杭州深度求索人工智能基础技术研究有限公司。”成立时间才一年多”、”最近推出的V3已经能和OpenAI的4o媲美”、”训练成本不到600W美元”、”API定价仅是国内其他头部厂商几十分之一”、”APP已经在中美APP store登上免费应用榜首”； 以上是最近关于DeepS">
<meta property="og:type" content="article">
<meta property="og:title" content="DeepSeek的核心技术">
<meta property="og:url" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/index.html">
<meta property="og:site_name" content="Zhuang&#39;s Diary">
<meta property="og:description" content="一、关于DeepSeek公司及其大模型1.1 公司概况DeepSeek 2023年7月成立于杭州，是幻方量化旗下的子公司，全称是杭州深度求索人工智能基础技术研究有限公司。”成立时间才一年多”、”最近推出的V3已经能和OpenAI的4o媲美”、”训练成本不到600W美元”、”API定价仅是国内其他头部厂商几十分之一”、”APP已经在中美APP store登上免费应用榜首”； 以上是最近关于DeepS">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/1.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/2.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/3.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/4.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/5.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/6.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/7.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/8.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/9.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/10.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/11.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/12.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/13.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/14.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/15.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/16.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/17.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/18.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/19.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/20.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/21.jpg">
<meta property="og:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/22.jpg">
<meta property="article:published_time" content="2025-02-07T03:36:00.000Z">
<meta property="article:modified_time" content="2025-02-07T03:37:06.305Z">
<meta property="article:author" content="Weiming Zhuang">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="DeepSeek">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/1.jpg">


<link rel="canonical" href="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>DeepSeek的核心技术 | Zhuang's Diary</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhuang's Diary</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">言之有物，持之以恒</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E5%85%B3%E4%BA%8EDeepSeek%E5%85%AC%E5%8F%B8%E5%8F%8A%E5%85%B6%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.</span> <span class="nav-text">一、关于DeepSeek公司及其大模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-%E5%85%AC%E5%8F%B8%E6%A6%82%E5%86%B5"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 公司概况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 模型能力</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3%E8%AE%AD%E6%8E%A8%E6%88%90%E6%9C%AC"><span class="nav-number">1.3.</span> <span class="nav-text">1.3训推成本</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81DeepSeek%E8%AE%AD%E6%8E%A8%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF"><span class="nav-number">2.</span> <span class="nav-text">二、DeepSeek训推核心技术</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-DeepSeek-V3%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 DeepSeek-V3模型网络架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-DeepSeekMoE"><span class="nav-number">2.1.1.</span> <span class="nav-text">2.1.1 DeepSeekMoE</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-MLA-%E5%A4%9A%E5%A4%B4%E6%BD%9C%E5%9C%A8%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="nav-number">2.1.2.</span> <span class="nav-text">2.1.2 MLA 多头潜在注意力</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 训练推理核心技术</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-1-%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6HAI-LLM"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.1 训练框架HAI-LLM﻿</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95DualPipe-%E5%88%9B%E6%96%B0%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2.2 核心算法DualPipe-创新流水线并行算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-3-%E7%94%A8%E4%BA%8EFP8%E8%AE%AD%E7%BB%83%E7%9A%84%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E6%A1%86%E6%9E%B6"><span class="nav-number">2.2.3.</span> <span class="nav-text">2.2.3 用于FP8训练的混合精度框架</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-4-MTP%E7%9A%84%E8%AE%AD%E7%BB%83%E7%9B%AE%E6%A0%87"><span class="nav-number">2.2.4.</span> <span class="nav-text">2.2.4 MTP的训练目标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-5-%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88"><span class="nav-number">2.2.5.</span> <span class="nav-text">2.2.5 推理部署方案</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88DeepSeekV3%E8%AE%AD%E7%BB%83%E6%88%90%E6%9C%AC%E8%BF%99%E4%B9%88%E4%BD%8E%EF%BC%9F"><span class="nav-number">3.</span> <span class="nav-text">总结：为什么DeepSeekV3训练成本这么低？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AFDeepSeek%EF%BC%9F"><span class="nav-number">4.</span> <span class="nav-text">三、为什么是DeepSeek？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83"><span class="nav-number">5.</span> <span class="nav-text">四、个人思考</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">6.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Weiming Zhuang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">273</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">70</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/zhuangweiming/" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhuangweiming&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DeepSeek的核心技术
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-02-07 11:36:00 / Modified: 11:37:06" itemprop="dateCreated datePublished" datetime="2025-02-07T11:36:00+08:00">2025-02-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="一、关于DeepSeek公司及其大模型"><a href="#一、关于DeepSeek公司及其大模型" class="headerlink" title="一、关于DeepSeek公司及其大模型"></a>一、关于DeepSeek公司及其大模型</h2><h3 id="1-1-公司概况"><a href="#1-1-公司概况" class="headerlink" title="1.1 公司概况"></a>1.1 公司概况</h3><p>DeepSeek 2023年7月成立于杭州，是幻方量化旗下的子公司，全称是杭州深度求索人工智能基础技术研究有限公司。”成立时间才一年多”、”最近推出的V3已经能和OpenAI的4o媲美”、”训练成本不到600W美元”、”API定价仅是国内其他头部厂商几十分之一”、”APP已经在中美APP store登上免费应用榜首”；</p>
<p>以上是最近关于DeepSeek的一些新闻热点信息，下面我们从官网看下：<br>DeepSeek近半年相继推出了3个主要的大模型版本，分别是DeepSeek V2.5、DeepSeek V3、DeepSeek-R1（无一例外的都是用了MOE架构）。在这之前还推出了DeepSeek-VL、DeepSeek Coder、DeepSeek Math。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/1.jpg"></p>
<h3 id="1-2-模型能力"><a href="#1-2-模型能力" class="headerlink" title="1.2 模型能力"></a>1.2 模型能力</h3><p>DeepSeek模型已经对标国内Qwen、海外Llama、GPT 4o，从公布的榜单评测上看：DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/2.jpg"></p>
<p><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/3.jpg"></p>
<h3 id="1-3训推成本"><a href="#1-3训推成本" class="headerlink" title="1.3训推成本"></a>1.3训推成本</h3><p>推理成本(API报价)：百万Token输入价格能达到1元。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/4.jpg"><br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/5.jpg"><br>训练成本：从技术报告中看DeepSeek用的是H800的GPU做的训练，而且只有2千张左右的H800，整个V3的正式训练成本不超过600W美元。</p>
<blockquote>
<p>1、预训练阶段，每万亿的Token 训练V3使用 2048 个H800GPU集群，只需要 180K 个H800 GPU小时，大概 3.7 天(180000/2048/24)<br>2、整个预训练总耗时 2664K GPU小时（不到2个月），加上 上下文扩展和后训练，总耗时大概2788KGPU耗时。<br>3、按照 H800 每小时2美元租赁，总的训练成本不超过600W美元<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/6.jpg"></p>
</blockquote>
<p>这么低的推理和训练成本不由引出以下的问题：</p>
<ul>
<li>模型采用了什么样的网络架构？</li>
<li>训练的精度、框架和并行策略是怎样的？</li>
<li>模型的部署和优化方案是怎样的？</li>
<li>在硬件层的计算和通信上做了什么优化？</li>
</ul>
<h2 id="二、DeepSeek训推核心技术"><a href="#二、DeepSeek训推核心技术" class="headerlink" title="二、DeepSeek训推核心技术"></a>二、DeepSeek训推核心技术</h2><h3 id="2-1-DeepSeek-V3模型网络架构"><a href="#2-1-DeepSeek-V3模型网络架构" class="headerlink" title="2.1 DeepSeek-V3模型网络架构"></a>2.1 DeepSeek-V3模型网络架构</h3><p><strong>1) DeepSeekV3 整体预训练用了14.8万亿的高质量Token，2) 并且在后期做了SFT和RL，模型参数量达到 671B，但是每个Token仅激活37B参数。为了做到高效的推理和训练，3) DeepSeekV3自研了MLA注意力机制和无辅助损失负载均衡策略的MoE架构。</strong></p>
<p>从技术报告中看出，是经典的Transformer架构，比较亮眼的就是前馈网络使用的DeepSeekMoE架构、Attention机制使用MLA架构，其实这两个在DeepSeekV2模型已经被验证使用过。<br>与DeepSeek-V2相比，V3额外引入了一种<strong>无辅助损失的负载均衡策略</strong>，用于DeepSeekMoE，以减轻因需要保证Expert负载均衡而导致的性能下降。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/7.jpg"></p>
<h4 id="2-1-1-DeepSeekMoE"><a href="#2-1-1-DeepSeekMoE" class="headerlink" title="2.1.1 DeepSeekMoE"></a>2.1.1 DeepSeekMoE</h4><p>第一个将MoE架构引入Transformer网络的就是GShard架构了，与传统大模型架构相比，MoE架构在数据流转过程中集成了一个专家网络层。<br>可以看出传统的MoE基本两部分组成：Gating门控网络、稀疏MoE层；</p>
<blockquote>
<ul>
<li>稀疏 MoE 层: 这些层代替了传统 Transformer 模型中的前馈网络 (FFN) 层。MoE 层包含若干“专家”(例如 8 个)，每个专家本身是一个独立的神经网络。在实际应用中，这些专家通常是前馈网络 (FFN)，但它们也可以是更复杂的网络结构，甚至可以是 MoE 层本身，从而形成层级式的 MoE 结构。</li>
<li>门控网络或路由: 这个部分用于决定哪些Token被发送到哪个专家。Token的路由方式是 MoE 使用中的一个关键点，因为路由器由学习的参数组成，并且与网络的其他部分一同进行预训练。</li>
</ul>
</blockquote>
<p><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/8.jpg"><br>和传统的MoE架构相比，<strong>DeepSeekMoE使用更细粒度的专家，并将一些专家隔离为共享专家，减少专家间的知识冗余</strong>。<br>﻿<img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/9.jpg"></p>
<p><strong>门控网络路由策略</strong>：TopK表示第t个Token和所有路由专家计算出的亲和力分数中K个最高分数的集合，在DeepSeekV3中，使用sigmoid函数计算亲和力分数，然后在所有选择的亲和力分数中应用归一化来生成门控值。﻿<br>通常在MoE模型的训练过程中，不同专家因为路由策略的因素会导致接收的训练数据分布不均，比如所有的Token都被发送到只有少数几个受欢迎的专家，那么有些专家就可能没有被训练到。<br>业界通用的解决方案就是引入辅助损失，但是，有时候过大的辅助损失会损害模型性能。<br>为了在负载均衡和模型性能之间取得更好的平衡，DeepSeek开创了一种<strong>无辅助损失的负载均衡策略</strong>：为每个专家引入一个偏差项 bi，并将其添加到相应的亲和力分数 Si,t 中以确定top-K路由，具体来说：如果其对应的专家过载，我们将偏差项减少γ；如果其对应的专家负载不足，我们将偏差项增加γ，其中γ是一个称为偏差更新速度的超参数。</p>
<blockquote>
<p>门控网络本质上就是一个softmax叠加一个分类网络，那么辅助loss往往就是添加一个惩罚项，对输出过大的 logits 进行惩罚，鼓励模型生成更加适度的 logits 值，防止模型生成过于极端的输出。</p>
</blockquote>
<h4 id="2-1-2-MLA-多头潜在注意力"><a href="#2-1-2-MLA-多头潜在注意力" class="headerlink" title="2.1.2 MLA 多头潜在注意力"></a>2.1.2 MLA 多头潜在注意力</h4><p>﻿大模型推理过程KV Cache机制一般是限制推理效率的一大瓶颈，而标准的Transformer 架构里面的MHA架构会产出非常多的KV Cache，为了减少对应的KV Cache业界实践过很多方案，例如PagedAttention、多查询注意力（MQA）和分组查询注意力（GQA），但是性能相比原生的MHA有一定差距。﻿<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/10.jpg"><br>DeepSeek-V2，提出一种创新的注意力机制：多头潜在注意力（MLA）。<br>相比MQA的KV共用和GQA的KV分组，<strong>MLA的核心是注意力键和值的低秩联合压缩，以减少推理过程中的键值(KV)缓存</strong>。相比MHA具有更好的性能，但需要的 KV 缓存量要少得多。﻿<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/11.jpg"></p>
<blockquote>
<p>低秩矩阵是指其秩（rank）远小于其行数和列数的矩阵。<br>假设我们有一个矩阵，其实际结构允许它被分解为两个较小的矩阵的乘积。这种情况通常意味着原矩阵是低秩的。<br>假设我们有一个<code>4×5</code>的矩阵<code>A</code>，这个矩阵可以通过两个更小的矩阵的乘积来表示，比如一个<code>4×2</code>的矩阵<code>B</code>和一个<code>2×5</code>的矩阵<code>C</code>。这意味着原始矩阵<code>A</code>的信息可以通过这两个较小的矩阵来捕捉，表明<code>A</code>是一个低秩矩阵。</p>
</blockquote>
<p>低秩压缩计算核心过程：<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/12.jpg"><br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/13.jpg"><br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/14.jpg"><br>这里的 ht 表示第 t 个Token的输入，WDKV 表示KV的向下投影矩阵，将 ht 做降维压缩表示，实际得到 cKVt 就是要缓存的KV压缩隐向量；WUK和WUV是向上做升维的投影矩阵，将Token的压缩隐向量cKVt复原为原始KV矩阵；<br>MLA 模块架构图如下：<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/15.jpg"></p>
<h3 id="2-2-训练推理核心技术"><a href="#2-2-训练推理核心技术" class="headerlink" title="2.2 训练推理核心技术"></a>2.2 训练推理核心技术</h3><p><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/16.jpg"></p>
<h4 id="2-2-1-训练框架HAI-LLM"><a href="#2-2-1-训练框架HAI-LLM" class="headerlink" title="2.2.1 训练框架HAI-LLM﻿"></a>2.2.1 训练框架HAI-LLM﻿</h4><p>DeepSeek-V3在一个配备了2048个NVIDIA H800 GPU的集群上进行训练，使用的是自研的HAI-LLM框架，框架实现了四种并行训练方式：<strong>ZeRO 支持的数据并行、流水线并行、张量切片模型并行和序列并行</strong>。  <br>这种并行能力支持不同工作负载的需求，可以支持数万亿规模的超大模型并扩展到数千个 GPU，同时还自研了一些配套的高性能算子haiscale，可以帮助 HAI-LLM 极大优化大模型训练的显存效率和计算效率。</p>
<h4 id="2-2-2-核心算法DualPipe-创新流水线并行算法"><a href="#2-2-2-核心算法DualPipe-创新流水线并行算法" class="headerlink" title="2.2.2 核心算法DualPipe-创新流水线并行算法"></a>2.2.2 核心算法DualPipe-创新流水线并行算法</h4><p>i.通信计算重叠优化<br>DeepSeek-V3应用了16路流水线并行（PP），跨越8个节点的64路专家并行（EP），以及ZeRO-1数据并行（DP）。<br>与现有的流水线并行方法相比，<strong>DualPipe的流水线气泡更少</strong>。同时<strong>重叠了前向和后向过程中的计算和通信阶段，解决了跨节点专家并行引入的沉重通信开销的挑战</strong>。<br>DualPipe的关键思想是<strong>重叠一对单独的前向和后向块中的计算和通信</strong>：将每个块划分为四个组件：注意力、all-all调度、MLP和all-all组合</p>
<blockquote>
<p>例如，假设我们有两个计算块，A和B：<br>1.在块A进行前向传播计算时，可以同时进行块B的后向传播通信过程。<br>2.当块A完成前向传播计算后，开始它的通信过程；而块B则开始它的前向传播计算。</p>
</blockquote>
<p><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/17.jpg"><br>通过优化排列这些功能模块，并精确调控用于通信和计算的 GPU SM资源分配比例，系统能够在运行过程中有效隐藏全节点通信和 PP 通信开销。<br>可以看出DeepSeek在PP这块，做了大量的通信计算重叠优化，从技术报告中看出，即使是细粒度的all-all专家通信，all-all的通信开销几乎为0。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/18.jpg">
﻿</p>
<blockquote>
<ul>
<li>计算通信重叠<br>在深度学习大规模分布式训练过程中，通信的速度往往落后于计算的速度，如何在通信的gap期间内并行做一些计算就是高性能计算和通信重叠，是实现高效训练的关键因素。</li>
<li>流水线并行气泡问题<br>一些大的模型会采用流水线并行策略，将模型的不同层放在不同的GPU上，但是不同层之间有依赖关系，后面层需要等前面的计算完才能开始计算，会导致GPU在一段时间是闲置的，如下图所示：<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/19.jpg"></li>
</ul>
</blockquote>
<p>ii.跨节点全对全通信<br>DeepSeek还专门定制了高效的跨节点all-all通信内核(包括调度和组合)。<br>具体来说：跨节点 GPU 通过 IB 完全互连，节点内通信通过 NVLink 处理，每个Token最多调度到 4个节点，从而减少 IB 通信量。同时<strong>使用warp专业化技术做调度和组合的优化</strong>。</p>
<blockquote>
<p>在调度过程中，(1) IB 发送，(2) IB 到 NVLink 转发，以及 (3) NVLink 接收分别由各自的 warp 处理。分配给每个通信任务的 warp 数会根据所有 SM 上的实际工作负载动态调整。<br>在合并过程中，(1) NVLink 发送，(2) NVLink 到 IB 的转发和累积，以及 (3) IB 接收和累积也由动态调整的 warp 处理。</p>
</blockquote>
<p>通过这种方式，IB 和 NVLink 的通信实现完全重叠，每个 token 能够在不产生 NVLink 额外开销的情况下，在每个节点上平均高效选择 3.2 个专家。这意味着，虽然 DeepSeek-V3 实际只选择 8 个路由专家，但它可以将这个数字扩展到最多 13 个专家（4 个节点 × 3.2 个专家/节点），同时保持相同的通信成本。</p>
<blockquote>
<p>DSV3采用了1个共享专家和256个路由专家的MoE架构，每个token会激活8个路由专家。</p>
</blockquote>
<h4 id="2-2-3-用于FP8训练的混合精度框架"><a href="#2-2-3-用于FP8训练的混合精度框架" class="headerlink" title="2.2.3 用于FP8训练的混合精度框架"></a>2.2.3 用于FP8训练的混合精度框架</h4><p>这里并没有将全量参数FP8量化训练，大多数计算密集型操作都在FP8中进行，而一些关键操作则战略性地保留其原始数据格式，以平衡训练效率和数值稳定性。</p>
<p><strong>哪些算子启用FP8量化去计算？取舍逻辑是什么？</strong></p>
<ul>
<li>大多数核心计算过程，即 GEMM 运算，都以 FP8 精度实现</li>
<li>涉及对低精度计算的敏感性的算子，仍然需要更高的精度</li>
<li>一些低成本算子也可以使用更高的精度<br>以下组件保留了原始精度（例如，BF16 或 FP32）：Embedding模块、输出头、MoE 门控模块、Normalization 算子以及 Attention 算子。</li>
</ul>
<p><strong>如何提高低精度训练精度？</strong></p>
<ul>
<li>细粒度量化<blockquote>
<p>对激活，在token维度采用group-wise的量化(1<em>128)；对权重，采用128</em> 128的block-wise量化<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/20.jpg"></p>
</blockquote>
</li>
<li>提高累加精度<blockquote>
<p>在 TensorCore 上执行矩阵 MMA（矩阵乘法累加）操作时，每当累加达到一个间隔时，这些部分结果会被传输到 CUDA Cores 上的 FP32 寄存器中，并在那里进行FP32 精度的累加计算。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/21.jpg"></p>
</blockquote>
</li>
</ul>
<h4 id="2-2-4-MTP的训练目标"><a href="#2-2-4-MTP的训练目标" class="headerlink" title="2.2.4 MTP的训练目标"></a>2.2.4 MTP的训练目标</h4><p>DeepSeekV3训练过程设置了多Token预测的目标，从技术报告的消融实验看出，确实提高了模型在大多数评估基准上的性能，而且MTP模块还可以用于推理加速。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/22.jpg"></p>
<h4 id="2-2-5-推理部署方案"><a href="#2-2-5-推理部署方案" class="headerlink" title="2.2.5 推理部署方案"></a>2.2.5 推理部署方案</h4><p>DeepSeek-V3 整体参数量达到了671B，如此多的参数量，我们看下他的一个部署方案：<br><strong>推理部署采用了预填充(Prefilling)和解码(Decoding)分离的策略</strong>，确保了在线服务的高吞吐量和低延迟。通过冗余专家部署和动态路由策略，模型在推理时保持了高效的负载均衡。<br>整套部署方案下来基本是跨机分布式推理。</p>
<p>2.2.5.1 Prefill 阶段<br>这个阶段简单说就是并行处理用户的Prompt，将其转为KV Cache。</p>
<blockquote>
<p>预填充阶段的最小部署单元由4个节点组成，每个节点配备32个GPU。注意力部分采用4路张量并行（TP4）和序列并行（SP），并结合8路数据并行（DP8）。其较小的TP规模（4路）限制了TP通信的开销。对于MoE部分，我们使用32路专家并行（EP32）</p>
</blockquote>
<p>2.2.5.2 Decoder 阶段<br>这个阶段就是做自回归的每个Token的输出。</p>
<blockquote>
<p>解码阶段的最小部署单元由40个节点和320个GPU组成。注意力部分采用TP4和SP，结合DP80，而MoE部分使用EP320。对于MoE部分，每个GPU只承载一个专家，64个GPU负责承载冗余专家和共享专家﻿</p>
</blockquote>
<h2 id="总结：为什么DeepSeekV3训练成本这么低？"><a href="#总结：为什么DeepSeekV3训练成本这么低？" class="headerlink" title="总结：为什么DeepSeekV3训练成本这么低？"></a>总结：为什么DeepSeekV3训练成本这么低？</h2><p><strong>训练成本主要由模型架构以及训练架构所决定，而且两者一定是相辅相成。从报告中可以看出以下几个原因：</strong><br>I.<strong>MLA 机制</strong>：通过对KV做联合低秩压缩大幅减少KV Cache，相比业界从KV数量角度做KV Cache的减少，MLA 的压缩实现很考验研究团队的基本功。<br>II.<strong>FP8 训练</strong>：通过低精度计算减少了 GPU 内存使用和计算开销，技术报告中也提到FP8混合精度训练框架是首次在一个极大规模的模型上验证了其有效性，这一点也看出DeepSeek的Infra工程团队的底蕴。<br>III.<strong>MoE 架构</strong>：通过MoE稀疏激活机制大幅减少了计算量，相比Qwen和Llama的Dense架构有很大的训推先天优势，不过难题(专家的负载、通信、路由)也给到了Infra工程团队。</p>
<h2 id="三、为什么是DeepSeek？"><a href="#三、为什么是DeepSeek？" class="headerlink" title="三、为什么是DeepSeek？"></a>三、为什么是DeepSeek？</h2><p>在硅谷，类似DeepSeek这样的AI创新并不少有，只是这次是一家中国公司做出了这个动作，相比传统的‘美国创新、中国应用’的模式显得格外的让人兴奋。</p>
<p>从最近的一些访谈以及DeepSeek的技术报告中也能看出以下几点：<br>1、大模型是一个知识密集型产业，如何组织高密度人才？显然DeepSeek做到了。<br>2、大模型技术没有魔法，更多时候就是考验基本功和驱动力。<br>3、不以商业化为第一要义，很多时候能轻装上阵。</p>
<h2 id="四、个人思考"><a href="#四、个人思考" class="headerlink" title="四、个人思考"></a>四、个人思考</h2><p>1、长远来看，后续可能会有专门的适配Transformer架构的芯片，就像为卷积设计了ASIC芯片。<br>2、多Token预测、MoE架构可能很长一段时间都是大模型训推架构热门研究方向。<br>3、在国内做AI，应用始终会比基础研究有市场，更有话语权，但是基础创新和海外的代际差距会越来越小。<br>4、大模型训练和推理，软硬件是一个协同的生态，DeepSeek的出现将会促进AI全行业的更加快速且低成本的迭代。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>1、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.19737">Better &amp; Faster Large Language Models via Multi-token Prediction﻿</a><br>4、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.19437">DeepSeek-V3 Technical Report</a>﻿<br>5、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.04434">DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</a>﻿<br>6、<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/8423473404">deepseek v3的成本这么低的根本原因是什么？</a>﻿<br>7、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1811.06965">GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism</a> ﻿</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Weiming Zhuang
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/" title="DeepSeek的核心技术">https://zhuang-weiming.github.io/2025/02/07/DeepSeek的核心技术/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
              <a href="/tags/DeepSeek/" rel="tag"># DeepSeek</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/01/22/Common%20requirement%20of%20CBDC/" rel="prev" title="Common requirement of CBDC">
                  <i class="fa fa-chevron-left"></i> Common requirement of CBDC
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/02/08/DeepSeek-R1%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/" rel="next" title="DeepSeek-R1的核心技术">
                  DeepSeek-R1的核心技术 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Weiming Zhuang</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'none'
      },
      options: {
        renderActions: {
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css">

<script>
NexT.utils.loadComments('.gitalk-container', () => {
  NexT.utils.getScript('https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'bcfbeadd6147f39af62f',
      clientSecret: '36f4ca5368918536f72f6b3816b90c30f61effb3',
      repo        : 'willzhuang.github.io',
      owner       : 'WillZhuang',
      admin       : ['WillZhuang'],
      id          : '0c719228bb75bf6ce198dd981a8d59e8',
      proxy       : 'https://cors-anywhere.herokuapp.com/https://github.com/login/oauth/access_token',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render(document.querySelector('.gitalk-container'));
  }, window.Gitalk);
});
</script>

</body>
</html>
