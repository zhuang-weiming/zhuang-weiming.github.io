<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhuang-weiming.github.io","root":"/","images":"/images","scheme":"Muse","version":"8.3.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>
<meta property="og:type" content="website">
<meta property="og:title" content="Zhuang&#39;s Diary">
<meta property="og:url" content="https://zhuang-weiming.github.io/page/2/index.html">
<meta property="og:site_name" content="Zhuang&#39;s Diary">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Weiming Zhuang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://zhuang-weiming.github.io/page/2/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>
<title>Zhuang's Diary</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhuang's Diary</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">言之有物，持之以恒</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Weiming Zhuang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">271</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">70</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/zhuangweiming/" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhuangweiming&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhuang-weiming.github.io/2025/02/08/DeepSeek-R1%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/02/08/DeepSeek-R1%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/" class="post-title-link" itemprop="url">DeepSeek-R1的核心技术</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-02-08 12:00:00 / Modified: 23:37:27" itemprop="dateCreated datePublished" datetime="2025-02-08T12:00:00+08:00">2025-02-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="DeepSeek-R1的实施步骤"><a href="#DeepSeek-R1的实施步骤" class="headerlink" title="DeepSeek-R1的实施步骤"></a>DeepSeek-R1的实施步骤</h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/deepseek-ai/DeepSeek-R1">DeepSeek-R1</a>本身就是开源的，HuggingFace <a target="_blank" rel="noopener" href="https://github.com/huggingface/open-r1">Open R1 项目</a> ，  <a target="_blank" rel="noopener" href="https://github.com/simplescaling/s1">李飞飞团队s1项目</a> ， <a target="_blank" rel="noopener" href="https://github.com/hkust-nlp/simpleRL-reason">simpleRL-reason</a> 在部分复现DeepSeek R1，还有 <a target="_blank" rel="noopener" href="https://github.com/Jiayi-Pan/TinyZero">TinyZero 项目</a>在复现DeepSeek R1-Zero，又是为何？<br>根据 DeepSeek-R1 的技术报告，分3个步骤完成这个项目：</p>
<ul>
<li>第1步：用 DeepSeek-R1 蒸馏高质量语料库，来复制R1-Distill模型。</li>
<li>第2步：复制 DeepSeek (V3) 用来构建R1-Zero的纯强化学习（RL）pipeline。这可能涉及为数学、推理和代码整理新的大规模数据集。</li>
<li>第3步：通过多阶段训练，从基础模型过渡到RL版本。<br><img src="/2025/02/08/DeepSeek-R1%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/1.jpg"></li>
</ul>
<p>结合DeepSeek的官方技术报告来看，也就是说，Open R1项目首先要实现的，是用R1数据蒸馏小模型，看看效果是不是像DeepSeek说的那么好：</p>
<h2 id="DeepSeek-R1的实施效果"><a href="#DeepSeek-R1的实施效果" class="headerlink" title="DeepSeek-R1的实施效果"></a>DeepSeek-R1的实施效果</h2><p>DeepSeek开源了6个用R1蒸馏的小模型，其中蒸馏版Qwen-1.5甚至能在部分任务上超过GPT-4o。<br><img src="/2025/02/08/DeepSeek-R1%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/2.jpg"><br>接下来，就是按照DeepSeek所说，不用SFT，单纯依靠RL调教出R1-Zero，在R1-Zero的基础上复刻出性能逼近o1的R1模型。</p>
<p>其中R1技术报告讲到，DeepSeek-R1训练过程中引入了一个多阶段训练流程，具体包括以下4个阶段：</p>
<ol>
<li>冷启动<br> 用数千个长思维链（CoT）样本对基础模型进行监督微调（SFT），为模型提供初始的推理能力。</li>
<li>面向推理的强化学习<br> 在第一个SFT阶段的基础之上，用和训练R1-Zero相同的大规模强化学习方法，进一步提升模型的推理能力，特别是应对编程、数学、科学和逻辑推理任务的能力。</li>
<li>拒绝采样的监督微调<br> 再次使用监督微调（SFT），提升模型的非推理能力，如事实知识、对话能力等。</li>
<li>针对所有场景的强化学习<br> 这次强化学习的重点是让模型行为与人类偏好保持一致，提升模型的可用性和安全性。<h2 id="Open-R1做了什么？"><a href="#Open-R1做了什么？" class="headerlink" title="Open R1做了什么？"></a>Open R1做了什么？</h2>目前，在<a target="_blank" rel="noopener" href="https://github.com/huggingface/open-r1">open-r1 GitHub仓库</a>中，已经可以看到这几个文件：</li>
</ol>
<ul>
<li><p>GRPO（Grouped Relative Policy Optimization）实现，<code>grpo.py</code>: trains a model with GRPO on a given dataset.<br>  在 Open R1 发布后，GRPO已整合至TRL最新版本（<a href="https://link.zhihu.com/?target=https://x.com/QGallouedec/status/1884978284686905468">v0.14</a>，Jan 30, 2025）。该整合方案支持使用单个或多个奖励函数模型进行模型训练。GRPO 实现方案深度集成了 DeepSpeed ZeRO 1/2/3 分布式训练框架以实现多 GPU 扩展，并采用 vLLM 加速生成过程——这正是在线训练方法的主要性能瓶颈。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> GRPOConfig, GRPOTrainer</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;trl-lib/tldr&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dummy reward: rewards completions that are close to 20 characters</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reward_len</span>(<span class="params">completions, **kwargs</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [-<span class="built_in">abs</span>(<span class="number">20</span> - <span class="built_in">len</span>(completion)) <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line"></span><br><span class="line">training_args = GRPOConfig(output_dir=<span class="string">&quot;Qwen2-0.5B-GRPO&quot;</span>, logging_steps=<span class="number">10</span>)</span><br><span class="line">trainer = GRPOTrainer(</span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen2-0.5B-Instruct&quot;</span>,</span><br><span class="line">    reward_funcs=reward_len,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=dataset,</span><br><span class="line">)</span><br><span class="line">trainer.train()</span><br><span class="line"><span class="comment"># (Feb 2nd)仍存在显存占用过高的问题，我们正在通过性能剖析进行优化改进。</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>合成数据生成器，<code>generate.py</code>: generates synthetic data from a model using <a target="_blank" rel="noopener" href="https://github.com/argilla-io/distilabel">Distilabel</a>.<br>  R1 技术报告中最引人注目的发现之一是：主模型可用于生成合成推理轨迹，而基于该数据集微调的较小模型可获得与主模型相近的性能提升。因此Open R1自然希望复现该合成推理数据集，使社区能够在其他模型上进行微调实验。<br>  面对 R1 这类超大模型，核心挑战在于高效扩展生成规模。Open R1花费一周时间尝试了多种配置方案：该模型可部署在 2 个 8xH100 节点（16 块 H100 GPU）上，我们最初基于此配置使用 vLLM 作为推理服务器。但很快发现该方案存在性能瓶颈：由于 GPU 的 KV 缓存快速耗尽，吞吐量未达最优且仅支持 8 路并行请求。当缓存耗尽时，占用大量缓存资源的请求会被抢占；若配置为<code>PreemptionMode.RECOMPUTE</code>模式，这些请求将在显存释放后重新调度。为此我们切换至 4x8xH100 节点配置（共 32 块 H100 GPU）。该方案为 32 路并行请求提供了充足的显存余量，基本避免了因 100% 缓存占用导致的请求重新调度问题。初始阶段我们采用批量请求查询 vLLM 服务器，但很快发现批次中的长尾样本会导致GPU利用率波动——新批次需等待前一批次最后一个样本完成后才能开始处理。将批量推理切换为流式处理后，GPU利用率显著稳定。<br><img src="/2025/02/08/DeepSeek-R1%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/3.jpg"></p>
<p>  该优化仅需修改vLLM服务器的请求发送代码。批量推理代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># send requests in batches of 500</span></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> batch_generator(dataset, bs=<span class="number">500</span>):</span><br><span class="line">    active_tasks = []</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> batch:</span><br><span class="line">        task = asyncio.create_task(send_requests(row))</span><br><span class="line">        active_tasks.add(task)</span><br><span class="line">    <span class="keyword">if</span> active_tasks:</span><br><span class="line">        <span class="keyword">await</span> asyncio.gather(*active_tasks)</span><br></pre></td></tr></table></figure>
<p>  流式请求的新版代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">active_tasks = []</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="comment"># keep the total active requests under 500</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(active_tasks) &gt;= <span class="number">500</span>:</span><br><span class="line">        done, active_tasks = <span class="keyword">await</span> asyncio.wait(</span><br><span class="line">            active_tasks,</span><br><span class="line">            return_when=asyncio.FIRST_COMPLETED</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    task = asyncio.create_task(send_requests(row))</span><br><span class="line">    active_tasks.add(task)</span><br><span class="line"></span><br><span class="line"><span class="comment"># wait for all remaining tasks to complete</span></span><br><span class="line"><span class="keyword">if</span> active_tasks:</span><br><span class="line">    <span class="keyword">await</span> asyncio.gather(*active_tasks)</span><br><span class="line">    <span class="comment"># Open R1当前的生成速率已趋于稳定，但对于长查询被抢占时是否采用CPU 缓存策略仍需进一步探索。</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>实施监督微调训练代码，<code>sft.py</code>: performs a simple SFT of a model on a dataset.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Train via <span class="built_in">command</span> line</span></span><br><span class="line">accelerate launch --config_file=recipes/accelerate_configs/zero3.yaml src/open_r1/sft.py \</span><br><span class="line">    --model_name_or_path Qwen/Qwen2.5-1.5B-Instruct \</span><br><span class="line">    --dataset_name HuggingFaceH4/Bespoke-Stratos-17k \</span><br><span class="line">    --learning_rate 2.0e-5 \</span><br><span class="line">    --num_train_epochs 1 \</span><br><span class="line">    --packing \</span><br><span class="line">    --max_seq_length 4096 \</span><br><span class="line">    --per_device_train_batch_size 2 \</span><br><span class="line">    --gradient_accumulation_steps 8 \</span><br><span class="line">    --gradient_checkpointing \</span><br><span class="line">    --bf16 \</span><br><span class="line">    --output_dir data/Qwen2.5-1.5B-Open-R1-Distill</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Train via YAML config</span></span><br><span class="line">accelerate launch --config_file recipes/accelerate_configs/zero3.yaml src/openr1/sft.py \</span><br><span class="line">    recipes/Qwen/Qwen2.5-1.5B-Instruct/sft/config_demo.yaml</span><br></pre></td></tr></table></figure></li>
<li><p>训练和评估代码，<code>evaluate.py</code>: evaluates a model on the R1 benchmarks.</p>
</li>
</ul>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>社区在多个与R1相关的数据集项目上非常活跃，以下是一些亮点：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/bespokelabs/Bespoke-Stratos-17k">bespokelabs/Bespoke-Stratos-17k</a>：这是对 Berkeley Sky-T1 数据管线的复制，使用 DeepSeek-R1 创建一个包含问题、推理轨迹和答案的数据集。随后，这些数据被用于通过类似于 R1 论文中的蒸馏方法，微调 7B 和 32B 的 Qwen 模型。</li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k">open-thoughts/OpenThoughts-114k</a>：一个“开放的合成推理数据集，包含 114k 个高质量样本，涵盖数学、科学、代码和谜题”。这是 Open Thoughts 项目的一部分。</li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/cognitivecomputations/dolphin-r1">cognitivecomputations/dolphin-r1</a>：一个包含 80 万样本的数据集，样本来自 DeepSeek-R1、Gemini flash 以及来自 DolphinChat 的 20 万样本，目的是帮助训练 R1 风格的模型。</li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/ServiceNow-AI/R1-Distill-SFT">ServiceNow-AI/R1-Distill-SFT</a>：目前有 17,000 个样本，这是 ServiceNow 语言模型实验室为支持 Open-R1 工作而创建的数据集。</li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/NovaSky-AI/Sky-T1_data_17k">NovaSky-AI/Sky-T1_data_17k</a>：用于训练 Sky-T1-32B-Preview 的 17k 训练数据。最终数据包含来自 APPs 和 TACO 的 5k 编码数据，以及来自 NuminaMATH 数据集的 AIME、MATH 和 Olympiads 子集的 10k 数学数据。此外，我们还维护了来自 STILL-2 的 1k 科学和拼图数据。使用该数据集训练的模型成本不到 450 美元。</li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B">Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B</a>：这个数据集扩展了 <a target="_blank" rel="noopener" href="https://huggingface.co/papers/2406.08464">Magpie</a> 和方法，通过生成没有起始提示的指令数据来包括推理过程。指令由 Llama 3.1 70B Instruct 和 Llama 3.3 70B Instruct 生成，响应则由 DeepSeek-R1-Distill-Llama-70B 生成。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>SFT后，进步显著，怎么做到的？<br> 一是微调用的训练数据起到了一定作用；二是强制让模型延长思考时间（test time scaling），具体做法叫做（Budget Forcing）预算强制，也就是强制限制模型使用最大或最小 tokens 进行推理，以此控制模型的思考长度。<br> 为了尽可能延长模型的思考，他们将模型的思考放在标签内，当结束后，以 final answer 给出答案，同时，当 LLM 即将停止思考时，会强制输出 Wait 来迫使模型继续思考，通过这样的方式，模型会进入反思，并可能会发现自己的错误。<br> 推理时插入的“Wait”，也许会像当初的 Step by Step 一样，成为一个魔法 token。“这或许就是古人‘三思而后行’的哲学吧！”</li>
<li>R1 训练的步骤总结：<br> 1）精心选择若干条（如 8000 条）高质量的数据，<br> 2）通过让 Gemini/DeepSeek V3 补充完善思维链COT之后作为数据集，<br> 3）以开源的大模型（如 Qwen2.5-32B，Llama 3.1）为基座微调出结果(如 R1)。<br> 4）最后，在模型输出时，用（Budget Forcing）预算强制方法强行拉长模型的思考时长和输出 token，结果发现其在特定测试集上进步显著。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhuang-weiming.github.io/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/" class="post-title-link" itemprop="url">DeepSeek的核心技术</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-02-07 11:36:00 / Modified: 11:37:06" itemprop="dateCreated datePublished" datetime="2025-02-07T11:36:00+08:00">2025-02-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="一、关于DeepSeek公司及其大模型"><a href="#一、关于DeepSeek公司及其大模型" class="headerlink" title="一、关于DeepSeek公司及其大模型"></a>一、关于DeepSeek公司及其大模型</h2><h3 id="1-1-公司概况"><a href="#1-1-公司概况" class="headerlink" title="1.1 公司概况"></a>1.1 公司概况</h3><p>DeepSeek 2023年7月成立于杭州，是幻方量化旗下的子公司，全称是杭州深度求索人工智能基础技术研究有限公司。”成立时间才一年多”、”最近推出的V3已经能和OpenAI的4o媲美”、”训练成本不到600W美元”、”API定价仅是国内其他头部厂商几十分之一”、”APP已经在中美APP store登上免费应用榜首”；</p>
<p>以上是最近关于DeepSeek的一些新闻热点信息，下面我们从官网看下：<br>DeepSeek近半年相继推出了3个主要的大模型版本，分别是DeepSeek V2.5、DeepSeek V3、DeepSeek-R1（无一例外的都是用了MOE架构）。在这之前还推出了DeepSeek-VL、DeepSeek Coder、DeepSeek Math。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/1.jpg"></p>
<h3 id="1-2-模型能力"><a href="#1-2-模型能力" class="headerlink" title="1.2 模型能力"></a>1.2 模型能力</h3><p>DeepSeek模型已经对标国内Qwen、海外Llama、GPT 4o，从公布的榜单评测上看：DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/2.jpg"></p>
<p><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/3.jpg"></p>
<h3 id="1-3训推成本"><a href="#1-3训推成本" class="headerlink" title="1.3训推成本"></a>1.3训推成本</h3><p>推理成本(API报价)：百万Token输入价格能达到1元。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/4.jpg"><br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/5.jpg"><br>训练成本：从技术报告中看DeepSeek用的是H800的GPU做的训练，而且只有2千张左右的H800，整个V3的正式训练成本不超过600W美元。</p>
<blockquote>
<p>1、预训练阶段，每万亿的Token 训练V3使用 2048 个H800GPU集群，只需要 180K 个H800 GPU小时，大概 3.7 天(180000/2048/24)<br>2、整个预训练总耗时 2664K GPU小时（不到2个月），加上 上下文扩展和后训练，总耗时大概2788KGPU耗时。<br>3、按照 H800 每小时2美元租赁，总的训练成本不超过600W美元<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/6.jpg"></p>
</blockquote>
<p>这么低的推理和训练成本不由引出以下的问题：</p>
<ul>
<li>模型采用了什么样的网络架构？</li>
<li>训练的精度、框架和并行策略是怎样的？</li>
<li>模型的部署和优化方案是怎样的？</li>
<li>在硬件层的计算和通信上做了什么优化？</li>
</ul>
<h2 id="二、DeepSeek训推核心技术"><a href="#二、DeepSeek训推核心技术" class="headerlink" title="二、DeepSeek训推核心技术"></a>二、DeepSeek训推核心技术</h2><h3 id="2-1-DeepSeek-V3模型网络架构"><a href="#2-1-DeepSeek-V3模型网络架构" class="headerlink" title="2.1 DeepSeek-V3模型网络架构"></a>2.1 DeepSeek-V3模型网络架构</h3><p><strong>1) DeepSeekV3 整体预训练用了14.8万亿的高质量Token，2) 并且在后期做了SFT和RL，模型参数量达到 671B，但是每个Token仅激活37B参数。为了做到高效的推理和训练，3) DeepSeekV3自研了MLA注意力机制和无辅助损失负载均衡策略的MoE架构。</strong></p>
<p>从技术报告中看出，是经典的Transformer架构，比较亮眼的就是前馈网络使用的DeepSeekMoE架构、Attention机制使用MLA架构，其实这两个在DeepSeekV2模型已经被验证使用过。<br>与DeepSeek-V2相比，V3额外引入了一种<strong>无辅助损失的负载均衡策略</strong>，用于DeepSeekMoE，以减轻因需要保证Expert负载均衡而导致的性能下降。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/7.jpg"></p>
<h4 id="2-1-1-DeepSeekMoE"><a href="#2-1-1-DeepSeekMoE" class="headerlink" title="2.1.1 DeepSeekMoE"></a>2.1.1 DeepSeekMoE</h4><p>第一个将MoE架构引入Transformer网络的就是GShard架构了，与传统大模型架构相比，MoE架构在数据流转过程中集成了一个专家网络层。<br>可以看出传统的MoE基本两部分组成：Gating门控网络、稀疏MoE层；</p>
<blockquote>
<ul>
<li>稀疏 MoE 层: 这些层代替了传统 Transformer 模型中的前馈网络 (FFN) 层。MoE 层包含若干“专家”(例如 8 个)，每个专家本身是一个独立的神经网络。在实际应用中，这些专家通常是前馈网络 (FFN)，但它们也可以是更复杂的网络结构，甚至可以是 MoE 层本身，从而形成层级式的 MoE 结构。</li>
<li>门控网络或路由: 这个部分用于决定哪些Token被发送到哪个专家。Token的路由方式是 MoE 使用中的一个关键点，因为路由器由学习的参数组成，并且与网络的其他部分一同进行预训练。</li>
</ul>
</blockquote>
<p><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/8.jpg"><br>和传统的MoE架构相比，<strong>DeepSeekMoE使用更细粒度的专家，并将一些专家隔离为共享专家，减少专家间的知识冗余</strong>。<br>﻿<img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/9.jpg"></p>
<p><strong>门控网络路由策略</strong>：TopK表示第t个Token和所有路由专家计算出的亲和力分数中K个最高分数的集合，在DeepSeekV3中，使用sigmoid函数计算亲和力分数，然后在所有选择的亲和力分数中应用归一化来生成门控值。﻿<br>通常在MoE模型的训练过程中，不同专家因为路由策略的因素会导致接收的训练数据分布不均，比如所有的Token都被发送到只有少数几个受欢迎的专家，那么有些专家就可能没有被训练到。<br>业界通用的解决方案就是引入辅助损失，但是，有时候过大的辅助损失会损害模型性能。<br>为了在负载均衡和模型性能之间取得更好的平衡，DeepSeek开创了一种<strong>无辅助损失的负载均衡策略</strong>：为每个专家引入一个偏差项 bi，并将其添加到相应的亲和力分数 Si,t 中以确定top-K路由，具体来说：如果其对应的专家过载，我们将偏差项减少γ；如果其对应的专家负载不足，我们将偏差项增加γ，其中γ是一个称为偏差更新速度的超参数。</p>
<blockquote>
<p>门控网络本质上就是一个softmax叠加一个分类网络，那么辅助loss往往就是添加一个惩罚项，对输出过大的 logits 进行惩罚，鼓励模型生成更加适度的 logits 值，防止模型生成过于极端的输出。</p>
</blockquote>
<h4 id="2-1-2-MLA-多头潜在注意力"><a href="#2-1-2-MLA-多头潜在注意力" class="headerlink" title="2.1.2 MLA 多头潜在注意力"></a>2.1.2 MLA 多头潜在注意力</h4><p>﻿大模型推理过程KV Cache机制一般是限制推理效率的一大瓶颈，而标准的Transformer 架构里面的MHA架构会产出非常多的KV Cache，为了减少对应的KV Cache业界实践过很多方案，例如PagedAttention、多查询注意力（MQA）和分组查询注意力（GQA），但是性能相比原生的MHA有一定差距。﻿<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/10.jpg"><br>DeepSeek-V2，提出一种创新的注意力机制：多头潜在注意力（MLA）。<br>相比MQA的KV共用和GQA的KV分组，<strong>MLA的核心是注意力键和值的低秩联合压缩，以减少推理过程中的键值(KV)缓存</strong>。相比MHA具有更好的性能，但需要的 KV 缓存量要少得多。﻿<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/11.jpg"></p>
<blockquote>
<p>低秩矩阵是指其秩（rank）远小于其行数和列数的矩阵。<br>假设我们有一个矩阵，其实际结构允许它被分解为两个较小的矩阵的乘积。这种情况通常意味着原矩阵是低秩的。<br>假设我们有一个<code>4×5</code>的矩阵<code>A</code>，这个矩阵可以通过两个更小的矩阵的乘积来表示，比如一个<code>4×2</code>的矩阵<code>B</code>和一个<code>2×5</code>的矩阵<code>C</code>。这意味着原始矩阵<code>A</code>的信息可以通过这两个较小的矩阵来捕捉，表明<code>A</code>是一个低秩矩阵。</p>
</blockquote>
<p>低秩压缩计算核心过程：<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/12.jpg"><br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/13.jpg"><br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/14.jpg"><br>这里的 ht 表示第 t 个Token的输入，WDKV 表示KV的向下投影矩阵，将 ht 做降维压缩表示，实际得到 cKVt 就是要缓存的KV压缩隐向量；WUK和WUV是向上做升维的投影矩阵，将Token的压缩隐向量cKVt复原为原始KV矩阵；<br>MLA 模块架构图如下：<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/15.jpg"></p>
<h3 id="2-2-训练推理核心技术"><a href="#2-2-训练推理核心技术" class="headerlink" title="2.2 训练推理核心技术"></a>2.2 训练推理核心技术</h3><p><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/16.jpg"></p>
<h4 id="2-2-1-训练框架HAI-LLM"><a href="#2-2-1-训练框架HAI-LLM" class="headerlink" title="2.2.1 训练框架HAI-LLM﻿"></a>2.2.1 训练框架HAI-LLM﻿</h4><p>DeepSeek-V3在一个配备了2048个NVIDIA H800 GPU的集群上进行训练，使用的是自研的HAI-LLM框架，框架实现了四种并行训练方式：<strong>ZeRO 支持的数据并行、流水线并行、张量切片模型并行和序列并行</strong>。  <br>这种并行能力支持不同工作负载的需求，可以支持数万亿规模的超大模型并扩展到数千个 GPU，同时还自研了一些配套的高性能算子haiscale，可以帮助 HAI-LLM 极大优化大模型训练的显存效率和计算效率。</p>
<h4 id="2-2-2-核心算法DualPipe-创新流水线并行算法"><a href="#2-2-2-核心算法DualPipe-创新流水线并行算法" class="headerlink" title="2.2.2 核心算法DualPipe-创新流水线并行算法"></a>2.2.2 核心算法DualPipe-创新流水线并行算法</h4><p>i.通信计算重叠优化<br>DeepSeek-V3应用了16路流水线并行（PP），跨越8个节点的64路专家并行（EP），以及ZeRO-1数据并行（DP）。<br>与现有的流水线并行方法相比，<strong>DualPipe的流水线气泡更少</strong>。同时<strong>重叠了前向和后向过程中的计算和通信阶段，解决了跨节点专家并行引入的沉重通信开销的挑战</strong>。<br>DualPipe的关键思想是<strong>重叠一对单独的前向和后向块中的计算和通信</strong>：将每个块划分为四个组件：注意力、all-all调度、MLP和all-all组合</p>
<blockquote>
<p>例如，假设我们有两个计算块，A和B：<br>1.在块A进行前向传播计算时，可以同时进行块B的后向传播通信过程。<br>2.当块A完成前向传播计算后，开始它的通信过程；而块B则开始它的前向传播计算。</p>
</blockquote>
<p><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/17.jpg"><br>通过优化排列这些功能模块，并精确调控用于通信和计算的 GPU SM资源分配比例，系统能够在运行过程中有效隐藏全节点通信和 PP 通信开销。<br>可以看出DeepSeek在PP这块，做了大量的通信计算重叠优化，从技术报告中看出，即使是细粒度的all-all专家通信，all-all的通信开销几乎为0。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/18.jpg">
﻿</p>
<blockquote>
<ul>
<li>计算通信重叠<br>在深度学习大规模分布式训练过程中，通信的速度往往落后于计算的速度，如何在通信的gap期间内并行做一些计算就是高性能计算和通信重叠，是实现高效训练的关键因素。</li>
<li>流水线并行气泡问题<br>一些大的模型会采用流水线并行策略，将模型的不同层放在不同的GPU上，但是不同层之间有依赖关系，后面层需要等前面的计算完才能开始计算，会导致GPU在一段时间是闲置的，如下图所示：<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/19.jpg"></li>
</ul>
</blockquote>
<p>ii.跨节点全对全通信<br>DeepSeek还专门定制了高效的跨节点all-all通信内核(包括调度和组合)。<br>具体来说：跨节点 GPU 通过 IB 完全互连，节点内通信通过 NVLink 处理，每个Token最多调度到 4个节点，从而减少 IB 通信量。同时<strong>使用warp专业化技术做调度和组合的优化</strong>。</p>
<blockquote>
<p>在调度过程中，(1) IB 发送，(2) IB 到 NVLink 转发，以及 (3) NVLink 接收分别由各自的 warp 处理。分配给每个通信任务的 warp 数会根据所有 SM 上的实际工作负载动态调整。<br>在合并过程中，(1) NVLink 发送，(2) NVLink 到 IB 的转发和累积，以及 (3) IB 接收和累积也由动态调整的 warp 处理。</p>
</blockquote>
<p>通过这种方式，IB 和 NVLink 的通信实现完全重叠，每个 token 能够在不产生 NVLink 额外开销的情况下，在每个节点上平均高效选择 3.2 个专家。这意味着，虽然 DeepSeek-V3 实际只选择 8 个路由专家，但它可以将这个数字扩展到最多 13 个专家（4 个节点 × 3.2 个专家/节点），同时保持相同的通信成本。</p>
<blockquote>
<p>DSV3采用了1个共享专家和256个路由专家的MoE架构，每个token会激活8个路由专家。</p>
</blockquote>
<h4 id="2-2-3-用于FP8训练的混合精度框架"><a href="#2-2-3-用于FP8训练的混合精度框架" class="headerlink" title="2.2.3 用于FP8训练的混合精度框架"></a>2.2.3 用于FP8训练的混合精度框架</h4><p>这里并没有将全量参数FP8量化训练，大多数计算密集型操作都在FP8中进行，而一些关键操作则战略性地保留其原始数据格式，以平衡训练效率和数值稳定性。</p>
<p><strong>哪些算子启用FP8量化去计算？取舍逻辑是什么？</strong></p>
<ul>
<li>大多数核心计算过程，即 GEMM 运算，都以 FP8 精度实现</li>
<li>涉及对低精度计算的敏感性的算子，仍然需要更高的精度</li>
<li>一些低成本算子也可以使用更高的精度<br>以下组件保留了原始精度（例如，BF16 或 FP32）：Embedding模块、输出头、MoE 门控模块、Normalization 算子以及 Attention 算子。</li>
</ul>
<p><strong>如何提高低精度训练精度？</strong></p>
<ul>
<li>细粒度量化<blockquote>
<p>对激活，在token维度采用group-wise的量化(1<em>128)；对权重，采用128</em> 128的block-wise量化<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/20.jpg"></p>
</blockquote>
</li>
<li>提高累加精度<blockquote>
<p>在 TensorCore 上执行矩阵 MMA（矩阵乘法累加）操作时，每当累加达到一个间隔时，这些部分结果会被传输到 CUDA Cores 上的 FP32 寄存器中，并在那里进行FP32 精度的累加计算。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/21.jpg"></p>
</blockquote>
</li>
</ul>
<h4 id="2-2-4-MTP的训练目标"><a href="#2-2-4-MTP的训练目标" class="headerlink" title="2.2.4 MTP的训练目标"></a>2.2.4 MTP的训练目标</h4><p>DeepSeekV3训练过程设置了多Token预测的目标，从技术报告的消融实验看出，确实提高了模型在大多数评估基准上的性能，而且MTP模块还可以用于推理加速。<br><img src="/2025/02/07/DeepSeek%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/22.jpg"></p>
<h4 id="2-2-5-推理部署方案"><a href="#2-2-5-推理部署方案" class="headerlink" title="2.2.5 推理部署方案"></a>2.2.5 推理部署方案</h4><p>DeepSeek-V3 整体参数量达到了671B，如此多的参数量，我们看下他的一个部署方案：<br><strong>推理部署采用了预填充(Prefilling)和解码(Decoding)分离的策略</strong>，确保了在线服务的高吞吐量和低延迟。通过冗余专家部署和动态路由策略，模型在推理时保持了高效的负载均衡。<br>整套部署方案下来基本是跨机分布式推理。</p>
<p>2.2.5.1 Prefill 阶段<br>这个阶段简单说就是并行处理用户的Prompt，将其转为KV Cache。</p>
<blockquote>
<p>预填充阶段的最小部署单元由4个节点组成，每个节点配备32个GPU。注意力部分采用4路张量并行（TP4）和序列并行（SP），并结合8路数据并行（DP8）。其较小的TP规模（4路）限制了TP通信的开销。对于MoE部分，我们使用32路专家并行（EP32）</p>
</blockquote>
<p>2.2.5.2 Decoder 阶段<br>这个阶段就是做自回归的每个Token的输出。</p>
<blockquote>
<p>解码阶段的最小部署单元由40个节点和320个GPU组成。注意力部分采用TP4和SP，结合DP80，而MoE部分使用EP320。对于MoE部分，每个GPU只承载一个专家，64个GPU负责承载冗余专家和共享专家﻿</p>
</blockquote>
<h2 id="总结：为什么DeepSeekV3训练成本这么低？"><a href="#总结：为什么DeepSeekV3训练成本这么低？" class="headerlink" title="总结：为什么DeepSeekV3训练成本这么低？"></a>总结：为什么DeepSeekV3训练成本这么低？</h2><p><strong>训练成本主要由模型架构以及训练架构所决定，而且两者一定是相辅相成。从报告中可以看出以下几个原因：</strong><br>I.<strong>MLA 机制</strong>：通过对KV做联合低秩压缩大幅减少KV Cache，相比业界从KV数量角度做KV Cache的减少，MLA 的压缩实现很考验研究团队的基本功。<br>II.<strong>FP8 训练</strong>：通过低精度计算减少了 GPU 内存使用和计算开销，技术报告中也提到FP8混合精度训练框架是首次在一个极大规模的模型上验证了其有效性，这一点也看出DeepSeek的Infra工程团队的底蕴。<br>III.<strong>MoE 架构</strong>：通过MoE稀疏激活机制大幅减少了计算量，相比Qwen和Llama的Dense架构有很大的训推先天优势，不过难题(专家的负载、通信、路由)也给到了Infra工程团队。</p>
<h2 id="三、为什么是DeepSeek？"><a href="#三、为什么是DeepSeek？" class="headerlink" title="三、为什么是DeepSeek？"></a>三、为什么是DeepSeek？</h2><p>在硅谷，类似DeepSeek这样的AI创新并不少有，只是这次是一家中国公司做出了这个动作，相比传统的‘美国创新、中国应用’的模式显得格外的让人兴奋。</p>
<p>从最近的一些访谈以及DeepSeek的技术报告中也能看出以下几点：<br>1、大模型是一个知识密集型产业，如何组织高密度人才？显然DeepSeek做到了。<br>2、大模型技术没有魔法，更多时候就是考验基本功和驱动力。<br>3、不以商业化为第一要义，很多时候能轻装上阵。</p>
<h2 id="四、个人思考"><a href="#四、个人思考" class="headerlink" title="四、个人思考"></a>四、个人思考</h2><p>1、长远来看，后续可能会有专门的适配Transformer架构的芯片，就像为卷积设计了ASIC芯片。<br>2、多Token预测、MoE架构可能很长一段时间都是大模型训推架构热门研究方向。<br>3、在国内做AI，应用始终会比基础研究有市场，更有话语权，但是基础创新和海外的代际差距会越来越小。<br>4、大模型训练和推理，软硬件是一个协同的生态，DeepSeek的出现将会促进AI全行业的更加快速且低成本的迭代。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>1、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.19737">Better &amp; Faster Large Language Models via Multi-token Prediction﻿</a><br>4、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.19437">DeepSeek-V3 Technical Report</a>﻿<br>5、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.04434">DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</a>﻿<br>6、<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/8423473404">deepseek v3的成本这么低的根本原因是什么？</a>﻿<br>7、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1811.06965">GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism</a> ﻿</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhuang-weiming.github.io/2025/01/22/Common%20requirement%20of%20CBDC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/22/Common%20requirement%20of%20CBDC/" class="post-title-link" itemprop="url">Common requirement of CBDC</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-01-22 17:00:00 / Modified: 17:08:02" itemprop="dateCreated datePublished" datetime="2025-01-22T17:00:00+08:00">2025-01-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="CBDC商业需求的框架："><a href="#CBDC商业需求的框架：" class="headerlink" title="CBDC商业需求的框架："></a>CBDC商业需求的框架：</h2><ol>
<li><p>货币属性与分层（Monetary Hierarchy）<br>• 明确性增强：<br>建议进一步明确CBDC与现有货币（如现钞、存款货币）在法律地位和功能上的边界，特别是CBDC与稳定币的关系，以防止市场混淆。<br>• 计息机制补充：<br>动态利率调控应细化适用场景，如是否适用于长期零利率环境或应对通缩危机。增加对“负利率”选项的讨论（如欧盟报告提及），并评估其可能对现金的替代效应和公众接受度的影响。</p>
</li>
<li><p>合规与监管（Compliance &amp; Regulation）<br>• 隐私与监管平衡细化：<br> • 对于“小额匿名交易”的标准可结合具体国情调整，比如中国试点采用的「可控匿名」方案，可以在技术上设置交易金额、频率的动态监控上限，而非固定金额阈值。<br> • 增加数据最小化（Data Minimization）原则，以减少不必要的信息收集，从而增强用户隐私保护。<br>• 制裁合规优化：<br>建议进一步细化跨境交易黑名单机制的实现方式，是否支持智能合约自动筛查，同时预防潜在的技术误判和冤假错案。</p>
</li>
<li><p>技术架构（Technical Infrastructure）<br>• 混合账本的弹性：<br>明确不同机构的技术分工，例如央行核心账本是采用传统集中式数据库，还是许可链。对于子账本的具体功能，可以进一步说明其扩展范围（如钱包、支付场景）以及与核心账本的交互机制。<br>• 隐私保护技术：<br>除零知识证明（ZKP）和同态加密外，可增加多方安全计算（MPC）的讨论，特别是对于跨境支付中的敏感数据分割与安全计算的适用性分析。<br>• 可扩展性补充：<br>万级TPS的标准可细化到压力测试指标，如峰值负载下的系统响应时间、区块生成时间和网络延迟等。</p>
</li>
<li><p>支付系统互操作性（Interoperability）<br>• 增强描述：<br>增加CBDC在跨境支付场景中的“桥接角色”功能说明，例如mBridge、ICE项目的架构特点；明确自动外汇兑换的具体技术实现（是否基于去中心化市场或官方清算系统）。<br>• 与商业银行系统的协同：<br>明确CBDC是否会与商业银行账户体系直接交互，以及在支付链条中，如何避免资源争夺（如存款转移至CBDC后对商业银行的影响）。</p>
</li>
<li><p>用户体验与普惠性（User-Centric Design）<br>• 普惠性增强：<br> • 硬件钱包的支持范围可进一步说明，如是否采用低成本芯片（例如安全芯片SE），以应对农村或偏远地区普及难题。<br> • 对无智能手机用户的支持还可以讨论二维码与短信支付结合方案。<br>• 双离线能力补充：<br>增加离线交易后同步验证机制的技术细节（如通过时间戳或单次签名以防双花攻击）。</p>
</li>
<li><p>货币政策传导（Monetary Policy Implementation）<br>• 定向发放机制优化：<br>明确技术实现，例如智能合约中的补贴精确传导机制，并讨论此类功能对社会福利政策的潜在影响（如精准扶贫）。<br>• 数据采集分析透明性：<br>增加对数据使用的透明化要求，例如统计数据是否匿名化处理以及其公开程度，以增强公众信任。</p>
</li>
<li><p>法律与治理框架（Legal &amp; Governance）<br>• 治理多元化：<br>增加外部监督机制，例如是否允许第三方审计机构对央行CBDC系统进行独立评估。<br>• 国际合作机制：<br>考虑到跨境支付需求，建议增加CBDC在国际治理框架中的角色说明，例如是否支持与IMF、BIS等国际组织协同制定技术标准。</p>
</li>
<li><p>CBDC参与方-央行，商业银行和金融中介等金融机构的权利，责任和义务。</p>
</li>
<li><p>补充建议<br>• 动态演进需求的细化：<br>对智能合约的可编程性增加限制性条款，以避免复杂合约逻辑引发系统性风险。同时可支持模块化智能合约，便于后期升级或维护。<br>• 技术中立性再明确：<br>技术中立性框架下，可列举具体的“避免绑定特定技术”的实现方法，例如通过开放API接口或支持多种基础设施并行部署。</p>
</li>
</ol>
<h2 id="CBDC继续需求的框架："><a href="#CBDC继续需求的框架：" class="headerlink" title="CBDC继续需求的框架："></a>CBDC继续需求的框架：</h2><p>核心目标：为公众和企业提供安全、可靠、高效、可普惠的数字支付手段，同时支持央行在货币政策、支付监管和金融创新中的核心职能。</p>
<h3 id="1-货币核心功能"><a href="#1-货币核心功能" class="headerlink" title="1. 货币核心功能"></a>1. 货币核心功能</h3><p>1.1 法定地位与可兑换性<br>• 法定货币属性：确保CBDC具有与纸币等值的货币权威性（M0级别），直接体现央行负债。<br>• 兑换机制：支持与现钞、商业银行存款的无缝兑换，保障CBDC与现有货币体系平稳共存。<br>• 多面额与精确支付：允许最低单位交易（如0.01元），满足日常交易需求。</p>
<p>1.2 利息与价值管理<br>• 默认无息设计：CBDC保持与纸币一致的零利率，避免对银行存款造成挤压。<br>• 动态调节选项：在特殊经济场景下（如通缩或危机）允许设计利息方案，支持货币政策工具创新。</p>
<h3 id="2-用户与场景需求"><a href="#2-用户与场景需求" class="headerlink" title="2. 用户与场景需求"></a>2. 用户与场景需求</h3><p>2.1 便捷性与普惠性<br>• 广泛的终端支持：兼容智能手机、非智能手机（如USSD短信支付），以及硬件钱包（适用于无银行账户用户）。<br>• 离线支付能力：在网络中断时支持小额支付（如公交、零售场景），同步额度可灵活设置（如3天内最高500元）。<br>• 普适设计：提供多语言界面、语音辅助功能，并支持残障人士友好的交互方式（如盲文触觉反馈）。</p>
<p>2.2 交易隐私保护<br>• 分层隐私：<br>    • 小额匿名交易：单笔&lt;100美元时，避免用户身份被记录；<br>    • 大额追溯交易：交易&gt;1000美元时，需绑定实名身份以满足合规要求。<br>• 用户数据保护：限制不必要的用户数据采集，确保数据在监管无需要的情况下可在设定时间后销毁（如90天）。</p>
<h3 id="3-支付与互操作性"><a href="#3-支付与互操作性" class="headerlink" title="3. 支付与互操作性"></a>3. 支付与互操作性</h3><p>3.1 国内支付整合<br>• 支付系统对接：支持CBDC与现有实时全额结算系统（RTGS）和其他支付网络的互联互通，保障T+0清算能力。<br>• 银行与钱包融合：允许用户将CBDC钱包与银行账户快速绑定，实现账户资金的灵活转移与管理。</p>
<p>3.2 跨境支付功能<br>• 跨境支付便捷性：通过多边央行合作（如mBridge项目）实现跨境支付无缝结算，并提供实时汇率支持。<br>• 合规性保障：在跨境支付中，实时筛查国际制裁名单，确保不涉及高风险交易。</p>
<h3 id="4-监管与合规支持"><a href="#4-监管与合规支持" class="headerlink" title="4. 监管与合规支持"></a>4. 监管与合规支持</h3><p>4.1 反洗钱（AML）与反恐融资（CFT）<br>• 实时监控：提供可疑交易的实时预警和链上追踪功能，确保资金来源与用途透明。<br>• 自动报告：支持生成符合国际标准的资金流动报告（如FATF旅行规则），减少金融机构合规负担。</p>
<p>4.2 账户管理与司法协助<br>• 账户冻结功能：在司法授权情况下，允许央行冻结特定用户的CBDC账户。<br>• 资金追回：支持误转账资金的快速追踪和人工审批返还流程。</p>
<h3 id="5-货币政策与数据支持"><a href="#5-货币政策与数据支持" class="headerlink" title="5. 货币政策与数据支持"></a>5. 货币政策与数据支持</h3><p>5.1 流动性与脱媒管理<br>• 余额上限：允许设置用户钱包的持币上限，避免商业银行存款大规模流失。<br>• 定向发放能力：支持政府专项资金（如灾害补贴）精准下发到用户钱包，提高政策执行效率。</p>
<p>5.2 数据驱动的经济监测<br>• 实时监测：通过交易数据流动情况（如频率、金额、地域分布）支持央行货币政策分析与调整。<br>• 宏观经济评估：基于CBDC的实时数据反馈，优化货币流通结构，替代传统滞后的M0统计方法。</p>
<h3 id="6-安全与稳定性"><a href="#6-安全与稳定性" class="headerlink" title="6. 安全与稳定性"></a>6. 安全与稳定性</h3><p>6.1 抗风险能力<br>• 高安全性：采用先进加密算法保护交易信息，确保CBDC对网络攻击（如量子计算攻击）具有抗风险能力。<br>• 离线交易风控：离线支付额度和时间窗可动态调整，防止双花攻击及恶意使用。</p>
<p>6.2 系统容灾<br>• 多活备份：在不同地区部署容灾节点，确保系统在灾难情况下的持续运行。<br>• 快速恢复：所有用户交易记录可在网络恢复后10分钟内同步，保障支付体验连续性。</p>
<h3 id="7-智能合约与可编程货币"><a href="#7-智能合约与可编程货币" class="headerlink" title="7. 智能合约与可编程货币"></a>7. 智能合约与可编程货币</h3><p>7.1 可编程场景<br>• 政府补贴发放：支持通过智能合约精确发放专项资金，确保资金流向符合政策目标。<br>• 绿色金融：支持碳积分兑换等创新应用，鼓励低碳消费行为。</p>
<p>7.2 合约管理与更新<br>• 部署权限：仅允许央行授权的机构发布智能合约，确保安全性与规范性。<br>• 动态升级：智能合约需支持紧急修复能力，避免代码漏洞引发系统性风险。</p>
<h3 id="8-附加说明"><a href="#8-附加说明" class="headerlink" title="8. 附加说明"></a>8. 附加说明</h3><p>• 动态调整需求：针对不同试点国家的具体需求（如普惠金融优先级或隐私保护程度），设计需灵活调整。<br>• 技术中立性：选择适配性广的基础架构，避免过度依赖单一技术，保障未来系统升级的灵活性。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhuang-weiming.github.io/2025/01/17/%E4%B8%80%E4%BA%9B%E5%8C%BA%E5%9D%97%E9%93%BE%E7%8A%AF%E7%BD%AA%E5%9C%B0%E5%9D%80%E7%9A%84%E6%A0%B7%E4%BE%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/17/%E4%B8%80%E4%BA%9B%E5%8C%BA%E5%9D%97%E9%93%BE%E7%8A%AF%E7%BD%AA%E5%9C%B0%E5%9D%80%E7%9A%84%E6%A0%B7%E4%BE%8B/" class="post-title-link" itemprop="url">一些区块链犯罪地址的样例</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-01-17 16:31:00" itemprop="dateCreated datePublished" datetime="2025-01-17T16:31:00+08:00">2025-01-17</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2025-01-20 11:35:32" itemprop="dateModified" datetime="2025-01-20T11:35:32+08:00">2025-01-20</time>
      </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <table>
<thead>
<tr>
<th><strong>Risk Category</strong></th>
<th><strong>Ethereum (fix 42 length)</strong></th>
<th><strong>Bitcoin (A string that starts with the letter 1 or 3 or bc1 )</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Sanction</td>
<td>0xfeed25Fc6Eae234c5eEfB3891cA18Bd4312a746f</td>
<td>32pTjxTNi7snk8sodrgfmdKao3DEn1nVJM</td>
</tr>
<tr>
<td>Criminal Organisation</td>
<td>0x098B716B8Aaf21512996dC57EB0615e2383E2f96</td>
<td>32pTjxTNi7snk8sodrgfmdKao3DEn1nVJM</td>
</tr>
<tr>
<td>Dark Market - Decentralised</td>
<td>0x8589427373d6d84e98730d7795d8f6f8731fda16</td>
<td>1CounterpartyXXXXXXXXXXXXXXXUWLpVr</td>
</tr>
<tr>
<td>Gambling</td>
<td>0x974CaA59e49682CdA0AD2bbe82983419A2ECC400</td>
<td>1dice8EMZmqKvrGE4Qc9bUFf9PX3xaYDp</td>
</tr>
<tr>
<td>Law Enforcement</td>
<td>0xdcbEfFBECcE100cCE9E4b153C4e15cB885643193</td>
<td>3LU8wRu4ZnXP4UM8Yo6kkTiGHM9BubgyiG</td>
</tr>
<tr>
<td>Malware</td>
<td>0x0A52eCAa61268C6a5Cf9Cd6b1378531A4672601B</td>
<td>1HB5XMLmzFVj8ALj6mfBsbifRoD4miY36v</td>
</tr>
<tr>
<td>Thief</td>
<td>0x9F12243D60c301d4E01a3d24bb620e8Ffb40f855</td>
<td>bc1qcygs9dl4pqw6atc4yqudrzd76p3r9cp6xp2kny 1HQ3Go3ggs8pFnXuHVHRytPCq5fGG8Hbhx</td>
</tr>
<tr>
<td>unknown (no risk so far)</td>
<td>0x6d2e03b7EfFEae98BD302A9F836D0d6Ab0002766</td>
<td>bc1pc24kj26d0hxh6xllcyedqazeqn7erqkykjhfepffxpp26ulq9a0q8q8vht</td>
</tr>
</tbody></table>
<p>Below are the characteristics of different types of Bitcoin addresses:</p>
<ol>
<li>P2PKH Address (Pay-to-PubKey-Hash):<br> • Starts with the letter “1”.<br> • Length is 26 to 35 characters.</li>
<li>P2SH Address (Pay-to-Script-Hash):<br> • Starts with the letter “3”.<br> • Length is 26 to 35 characters.</li>
<li>Bech32 Address (SegWit Address):<br> • Starts with “bc1”.<br> • Length is 42 to 62 characters.</li>
</ol>
<p>另外，Thief on Solana</p>
<ul>
<li>CEzN7mqP9xoxn2HdyW6fjEJ73t7qaX9Rp2zyS6hb3iEu  </li>
<li>5WwBYgQG6BdErM2nNNyUmQXfcUnB68b6kesxBywh1J3n  </li>
</ul>
<p>Scam on ETH</p>
<ul>
<li>0x84eb60e6732848f837f48402dcfff25e3d3d9304</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhuang-weiming.github.io/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/" class="post-title-link" itemprop="url">Web安全培训</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-12-10 17:00:00 / Modified: 17:36:33" itemprop="dateCreated datePublished" datetime="2024-12-10T17:00:00+08:00">2024-12-10</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="工具介绍"><a href="#工具介绍" class="headerlink" title="工具介绍"></a>工具介绍</h2><p>Burp 抓包，改包工具， 基于java，运行，需要JRE<br>需要搭梯子才能登录其网站主页，美国公司，商业软件，年费399年费，有社区开源版本<br><img src="/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/1.png"><br>Burp未启动时，网络的路由环境<br>    本地（浏览器） — 服务器<br>Burp启动后，网络的路由环境<br>    本地（浏览器 — Burp） — 服务器<br>Burp extensions — <a target="_blank" rel="noopener" href="https://github.com/snoopysecurity/awesome-burp-extensions">https://github.com/snoopysecurity/awesome-burp-extensions</a></p>
<p>DVWA靶场，里面是各种漏洞攻击的介绍和说明，是一个入门的联系资源，英文资源。<br><img src="/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/2.png"></p>
<p>Pikachu 漏洞练习平台，同理，中文资源。<br><img src="/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/3.png"></p>
<p><a target="_blank" rel="noopener" href="https://www.kali.org/">https://www.kali.org/</a> , 一个Linux发行版本，是专门针对各种信息安全任务或者练习而准备的。</p>
<h2 id="前端一切不可靠，如上Burp在客户端做网络流量拦截，做中间人攻击"><a href="#前端一切不可靠，如上Burp在客户端做网络流量拦截，做中间人攻击" class="headerlink" title="前端一切不可靠，如上Burp在客户端做网络流量拦截，做中间人攻击"></a>前端一切不可靠，如上Burp在客户端做网络流量拦截，做中间人攻击</h2><p>对应的措施：<br>1.后端校验；2.前端不做逻辑判断；3.前端加密混淆；4.移动端加壳；5.反调试检测，防止逆向工程; 6.后台数据库存储字段最好经过KMS后端密文，常见的服务器本地算法 — hash(明文+盐值)<br>通常，<a target="_blank" rel="noopener" href="http://www.website.com/robots.txt%EF%BC%8C%E5%A6%82">www.website.com/robots.txt，如</a> <a target="_blank" rel="noopener" href="https://www.bilibili.com/robots.txt">https://www.bilibili.com/robots.txt</a> ，很多网站都有这样子一个网站URL的列表，表示本网站允许访问的URL。</p>
<p>Burp 启动浏览器，在网站的<a target="_blank" rel="noopener" href="http://burp/%E5%9C%B0%E5%9D%80%EF%BC%8C">http://burp/地址，</a><br>在网页右上角点击CA Certificate 下载Burp颁发的证书。<br><img src="/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/4.png"></p>
<p>Burp暴力破解，尝试用户名和密码时，可以使用“Repeater”和“Intruder”两个菜单的功能。<br>通常登录成功后，response 的长度会有不同。<br><img src="/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/5.png"><br>暴力破解的本质是 自动化，大量发送请求，猜测密码。<br>应对方法：<br>1.要求用户密码设置的复杂度；<br>2.识别爬虫/机器人：验证码，滑块，随机验证码；<br>3.限制登录频率：每次登录n秒以上方可，错误m次后冻结该用户x分钟，这样会带来问题：<br>A.前端限制，通过重置本地数据可以绕过；<br>B.IP地址限制，可能会误封正常用户，攻击者租用地址池拥有大量IP。<br>C.账号限制，会造成正常用户无法登录，恶意攻击者可以制造拒绝服务攻击。<br>4.增加密码强度，特别是增加密码长度是最有效的强度。<br>A.密码一户一用，避免一个密码到处使用，避免撞库攻击。<br>密码的本质是进行身份验证的手段。<br>密码的应用场景是基于以下假设：只有用户和服务器知道该密码<br>其他方式验证身份：短信验证码，指纹，面部识别，USBKEY，2FA，多因子验证等等。</p>
<h2 id="社会工程"><a href="#社会工程" class="headerlink" title="社会工程"></a>社会工程</h2><p>黑客通过社会工程学（Social Engineering）实现攻击的手法多种多样，主要是利用人类的心理弱点和信任机制来获取信息或访问权限。<br>钓鱼攻击，尾随攻击，假冒身份，电话攻击，非技术性攻击，社交媒体欺骗，媒体投影攻击，关系建立攻击等等。<br><img src="/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/6.png"></p>
<h2 id="OWASP-—-Open-Web-Application-Security-Project"><a href="#OWASP-—-Open-Web-Application-Security-Project" class="headerlink" title="OWASP — Open Web Application Security Project"></a>OWASP — Open Web Application Security Project</h2><p>OWASP Top 10 提供了Web 安全领域发生最频繁的10种事故。最新版本是 2021 年发布的 — <a target="_blank" rel="noopener" href="https://owasp.org/Top10/zh_CN/">https://owasp.org/Top10/zh_CN/</a></p>
<p>WebShell - 以网页形式实现shell的功能，能够对系统进行操作。例如，文件读写，命令执行等。也被称为网页木马。<br>首先，网站如果对用户上传的文件，不做控制，黑客则有可能会上传木马文件，黑客通过木马文件控制后台服务器，如下，<br>通过 <a target="_blank" rel="noopener" href="https://github.com/AntSwordProject/">https://github.com/AntSwordProject/</a> 工具可以执行网页木马。<br><img src="/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/7.png"><br>执行木马 <?php eval($_POST['cmd']);?> 成功，成功访问到后端服务器的目录和文件。<br><img src="/2024/12/10/Web%E5%AE%89%E5%85%A8%E5%9F%B9%E8%AE%AD/8.png"></p>
<p>仅仅依赖客户端 JavaScript 验证和服务器端 MIME 类型检查仍然不够安全，因为客户端验证很容易被绕过，而且 MIME 类型本身也可能被伪造，尽管概率较低。 为了构建一个更加严谨的文件上传系统，需要采取更全面的安全措施，将验证和安全检查融入整个上传流程的各个阶段。</p>
<p>一个更严谨的文件上传系统应该包含以下措施：</p>
<ol>
<li>客户端验证 (加强):<br>文件类型检查 (加强): 虽然 file.type 相对可靠，但仍然不是绝对安全的。 可以考虑结合一些额外的检查：<br>文件头部信息检查: 读取文件的前几个字节，检查是否符合已知的文件格式规范。 这需要对不同文件类型的头部结构有深入的了解。 但这仍然只能作为辅助手段，不能完全依赖。<br>更严格的正则表达式: 使用更精确的正则表达式来验证文件名，但这仍然不能防止恶意文件伪装。<br>文件大小限制: 设置一个合理的文件大小限制，并进行客户端验证。<br>用户反馈: 提供清晰的用户反馈，告知用户文件上传失败的原因，例如文件类型不允许、文件大小超过限制等。<br>禁止直接拖拽上传: 避免用户直接拖拽文件到上传区域，强制用户通过“选择文件”按钮选择文件，这样可以更好地控制文件上传过程。</li>
<li>服务器端验证 (多层防御):<br>文件类型检查 (多重验证): 不要仅仅依靠 MIME 类型，结合多种方法进行验证：<br>文件签名: 检查文件的魔术数字 (magic number)，这是一种非常可靠的方法。 不同的文件格式通常有独特的魔术数字。<br>文件内容分析: 对于一些关键的文件类型，可以进行更深入的内容分析，检查文件结构是否符合规范。 这需要根据具体的文件类型定制相应的分析方法。 这可能需要耗费较多资源。<br>文件大小限制: 设置严格的文件大小限制，防止资源耗尽攻击(Denial of Service,DoS)。<br>临时文件存储: 将上传的文件先保存到一个临时目录，然后再进行后续处理，这样可以避免恶意文件直接影响服务器。<br>文件扩展名检查 (补充): 虽然不完全可靠，但作为附加的检查，可以辅助判断文件的类型。<br>内容安全扫描 (关键): 使用专业的安全扫描工具，扫描上传的文件是否包含恶意代码、病毒或其他有害内容。 这可能是最关键的安全步骤，但会增加系统复杂性和成本。 一些云服务提供商提供此类服务。<br>白名单机制: 只允许特定类型的文件上传。 尽量避免使用黑名单，因为黑名单很难完全覆盖所有的恶意文件类型。<br>沙盒环境: 在沙盒环境中执行文件分析，以最大程度地限制恶意代码对服务器的影响。<br>日志记录: 记录所有的文件上传事件，包括文件名、MIME 类型、文件大小、上传时间以及验证结果。 这有助于追踪和分析安全事件。</li>
<li>其他安全措施:<br>HTTPS: 使用 HTTPS 加密上传过程，防止数据被窃取。<br>输入验证: 对所有用户输入进行严格的验证，防止注入攻击。<br>代码安全审计: 定期对代码进行安全审计，查找和修复潜在的安全漏洞。<br>服务端代码示例，如下：<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;io&quot;</span></span><br><span class="line">	<span class="string">&quot;mime/multipart&quot;</span></span><br><span class="line">	<span class="string">&quot;net/http&quot;</span></span><br><span class="line">	<span class="string">&quot;os&quot;</span></span><br><span class="line">	<span class="string">&quot;path/filepath&quot;</span></span><br><span class="line">	<span class="string">&quot;regexp&quot;</span></span><br><span class="line">	<span class="string">&quot;strings&quot;</span></span><br><span class="line"></span><br><span class="line">	<span class="string">&quot;github.com/gabriel-vasile/mimetype&quot;</span> <span class="comment">// 用于更准确的 MIME 类型检测</span></span><br><span class="line">	<span class="string">&quot;github.com/google/uuid&quot;</span>             <span class="comment">// 用于生成唯一的文件名</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// AllowedMimeTypes 定义允许上传的文件类型</span></span><br><span class="line"><span class="keyword">var</span> AllowedMimeTypes = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">bool</span>&#123;</span><br><span class="line">	<span class="string">&quot;image/jpeg&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">	<span class="string">&quot;image/png&quot;</span>:  <span class="literal">true</span>,</span><br><span class="line">	<span class="string">&quot;image/gif&quot;</span>:  <span class="literal">true</span>,</span><br><span class="line">	<span class="comment">// 添加其他允许的 MIME 类型</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// MaxFileSize 定义允许上传的最大文件大小 (字节)</span></span><br><span class="line"><span class="keyword">const</span> MaxFileSize = <span class="number">10</span> * <span class="number">1024</span> * <span class="number">1024</span> <span class="comment">// 10MB</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// uploadHandler 处理文件上传请求</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">uploadHandler</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> r.Method != http.MethodPost &#123;</span><br><span class="line">		http.Error(w, <span class="string">&quot;Method Not Allowed&quot;</span>, http.StatusMethodNotAllowed)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	file, handler, err := r.FormFile(<span class="string">&quot;file&quot;</span>) <span class="comment">// 假设表单字段名为 &quot;file&quot;</span></span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		http.Error(w, err.Error(), http.StatusBadRequest)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">defer</span> file.Close()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 客户端验证 (加强)</span></span><br><span class="line">	fileName := handler.Filename</span><br><span class="line">	<span class="keyword">if</span> !isValidFileName(fileName) &#123; <span class="comment">// 检查文件名是否合法</span></span><br><span class="line">		http.Error(w, <span class="string">&quot;Invalid file name&quot;</span>, http.StatusBadRequest)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	fileSize := handler.Size</span><br><span class="line">	<span class="keyword">if</span> fileSize &gt; MaxFileSize &#123;</span><br><span class="line">		http.Error(w, <span class="string">&quot;File too large&quot;</span>, http.StatusRequestEntityTooLarge)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 服务器端验证 (多层防御)</span></span><br><span class="line">	detectedMimeType, err := mimetype.DetectReader(file)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		http.Error(w, <span class="string">&quot;Failed to detect MIME type&quot;</span>, http.StatusInternalServerError)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> !AllowedMimeTypes[detectedMimeType.String()] &#123;</span><br><span class="line">		http.Error(w, <span class="string">&quot;Invalid file type&quot;</span>, http.StatusBadRequest)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 使用 UUID 生成唯一的文件名，避免文件名冲突</span></span><br><span class="line">	newFileName := uuid.New().String() + filepath.Ext(fileName)</span><br><span class="line">	uploadPath := <span class="string">&quot;./uploads/&quot;</span> + newFileName <span class="comment">// 定义上传文件的存储路径</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 创建上传目录，如果不存在</span></span><br><span class="line">	os.MkdirAll(<span class="string">&quot;./uploads/&quot;</span>, <span class="number">0755</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 创建文件并保存</span></span><br><span class="line">	newFile, err := os.Create(uploadPath)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		http.Error(w, err.Error(), http.StatusInternalServerError)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">defer</span> newFile.Close()</span><br><span class="line"></span><br><span class="line">	_, err = io.Copy(newFile, file)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		http.Error(w, err.Error(), http.StatusInternalServerError)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//  此处添加更严格的安全检查，例如：</span></span><br><span class="line">	<span class="comment">//  1. 使用第三方库进行病毒扫描 (ClamAV, VirusTotal API 等)</span></span><br><span class="line">	<span class="comment">//  2. 更深入的文件内容分析，根据文件类型进行特定检查</span></span><br><span class="line"></span><br><span class="line">	fmt.Fprintf(w, <span class="string">&quot;File uploaded successfully: %s\n&quot;</span>, newFileName)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// isValidFileName 检查文件名是否合法，防止目录遍历攻击等</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">isValidFileName</span><span class="params">(fileName <span class="keyword">string</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	re := regexp.MustCompile(<span class="string">`^[a-zA-Z0-9._-]+$`</span>) <span class="comment">// 只允许字母、数字、点、下划线和短横线</span></span><br><span class="line">	<span class="keyword">return</span> re.MatchString(fileName)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	http.HandleFunc(<span class="string">&quot;/upload&quot;</span>, uploadHandler)</span><br><span class="line">	fmt.Println(<span class="string">&quot;Server listening on port 8080&quot;</span>)</span><br><span class="line">	http.ListenAndServe(<span class="string">&quot;:8080&quot;</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
AllowedMimeTypes: 定义了允许上传的文件类型，使用 map[string]bool 更易于管理。<br>MaxFileSize: 设置了最大文件大小限制。<br>mimetype 库: 使用了 github.com/gabriel-vasile/mimetype 库来更准确地检测 MIME 类型。 这比只依赖 handler.Header.Get(“Content-Type”) 更可靠。<br>UUID 生成文件名: 使用 UUID 生成唯一的文件名，避免文件名冲突和潜在的安全问题。<br>isValidFileName 函数: 对文件名进行简单的验证，防止目录遍历等攻击。 这只是一个基本的示例，实际应用中可能需要更复杂的验证规则。<br>临时文件存储 (缺失但建议): 为了更安全，应该先将文件保存到临时目录，验证通过后再移动到最终存储位置。<br>安全扫描 (缺失但必须): 代码中用注释标注了需要添加安全扫描的地方。 你需要集成一个专业的安全扫描库或服务 (例如 ClamAV, VirusTotal API 等) 来扫描上传的文件是否包含恶意代码。 这是至关重要的安全步骤。</li>
</ol>
<h2 id="Linux-系统排查"><a href="#Linux-系统排查" class="headerlink" title="Linux 系统排查"></a>Linux 系统排查</h2><p>1.查看用户行为<br>/etc/passwd，/etc/shadow 中存储了account和密码信息，黑客可能会增加高权限用户在如上两个文件夹中<br>如 macOS 中，<br>➜  ~ sudo dscl . -list /Users | while read user; do sudo dscl . -read /Users/“$user” UserShell | grep -q ‘/bin/bash’ &amp;&amp; echo $user; done<br>_mbsetupuser<br>postgres<br>➜  ~ last<br>Zzz  ttys000                         Tue Dec 10 14:05   still logged in<br>Zzz  ttys000                         Mon Dec  9 11:29 - 11:29  (00:00)<br>Zzz  ttys000                         Sat Dec  7 19:35 - 19:35  (00:00)<br>Zzz  console                         Tue Dec  3 14:51   still logged in<br>reboot time                                Tue Dec  3 14:50<br>还有，如查看用户的密码是否为空，用户执行过的命令，等等。<br>3.查看进程，例如，黑客通过服务器在挖矿等异常。lspf， top等命令。<br>更多可以查看 Linux 应急响应手册 — <a target="_blank" rel="noopener" href="https://github.com/Just-Hack-For-Fun/Linux-INCIDENT-RESPONSE-COOKBOOK">https://github.com/Just-Hack-For-Fun/Linux-INCIDENT-RESPONSE-COOKBOOK</a></p>
<h2 id="威胁情报中心："><a href="#威胁情报中心：" class="headerlink" title="威胁情报中心："></a>威胁情报中心：</h2><p>Windows 系统工具 - <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/sysinternals/">https://learn.microsoft.com/en-us/sysinternals/</a><br>腾讯威胁情报中心 - <a target="_blank" rel="noopener" href="https://tix.qq.com/">https://tix.qq.com/</a><br>可疑文件分析 - <a target="_blank" rel="noopener" href="https://www.virustotal.com/gui/home/upload">https://www.virustotal.com/gui/home/upload</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/55/">55</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>


<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Weiming Zhuang</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'none'
      },
      options: {
        renderActions: {
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>




</body>
</html>
