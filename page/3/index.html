<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"willzhuang.github.io","root":"/","images":"/images","scheme":"Muse","version":"8.3.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>
<meta property="og:type" content="website">
<meta property="og:title" content="Zhuang&#39;s Diary">
<meta property="og:url" content="https://willzhuang.github.io/page/3/index.html">
<meta property="og:site_name" content="Zhuang&#39;s Diary">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Weiming Zhuang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://willzhuang.github.io/page/3/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>
<title>Zhuang's Diary</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhuang's Diary</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">言之有物，持之以恒</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Weiming Zhuang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">234</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">58</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/zhuangweiming/" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhuangweiming&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://willzhuang.github.io/2023/10/13/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/13/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">如何测评大语言模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-13 15:42:00" itemprop="dateCreated datePublished" datetime="2023-10-13T15:42:00+08:00">2023-10-13</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-10-16 13:42:15" itemprop="dateModified" datetime="2023-10-16T13:42:15+08:00">2023-10-16</time>
      </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>大语言模型的评测方法是一个热门的研究话题，目前还没有一个统一的标准。不同的评测方法可能侧重于不同的方面，例如语言模型的生成能力、理解能力、泛化能力、对抗能力等。</p>
<h3 id="一些常见的评测方法有："><a href="#一些常见的评测方法有：" class="headerlink" title="一些常见的评测方法有："></a>一些常见的评测方法有：</h3><ul>
<li><strong>困惑度（Perplexity）</strong>：困惑度是一种衡量语言模型预测下一个词的准确性的指标，它反映了语言模型对文本的复杂度的估计。困惑度越低，说明语言模型越能够准确地预测下一个词，越能够流畅地生成文本。困惑度的计算公式是<br>$$PPL(W)= \exp \Big(− \frac{1}{N}​ \sum_{i=1}^{N} \log p(w_i​|w_{&lt;i​}) \Big)$$<br> 其中 W 是一个文本序列，N 是序列的长度，p(wi​ | w&lt;i​) 是语言模型给出的第 i 个词的条件概率。</li>
<li><strong>自动评价指标（Automatic Metrics）</strong>：自动评价指标是一种利用已有的参考文本来评价语言模型生成文本的质量的方法，它主要考察生成文本和参考文本之间的相似度。常用的自动评价指标有 <strong>BLEU</strong>、<strong>ROUGE</strong>、<strong>METEOR</strong>、<strong>BERTScore</strong> 等。这些指标通常基于词汇、语法、语义等层面来计算生成文本和参考文本之间的匹配程度，但是它们也存在一些局限性，例如忽略了生成文本的流畅性、逻辑性、创造性等方面。</li>
<li><strong>人工评价指标（Human Metrics）</strong>：人工评价指标是一种通过人类评估员来评价语言模型生成文本的质量的方法，它主要考察生成文本是否符合人类的期望和偏好。人工评价指标通常涉及多个维度，例如 <strong>流畅性（Fluency）</strong>、<strong>一致性（Consistency）</strong>、<strong>相关性（Relevance）</strong>、<strong>多样性（Diversity）</strong>、<strong>正确性（Correctness）</strong> 等。人工评价指标可以更好地反映生成文本的真实水平，但是它们也存在一些问题，例如成本高、效率低、主观性强等。</li>
</ul>
<h3 id="相关的论文如下："><a href="#相关的论文如下：" class="headerlink" title="相关的论文如下："></a>相关的论文如下：</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2102.04664">CodeXGLUE: A Benchmark Dataset and Open Challenge for Code Intelligence</a><br>[Storyline: A Benchmark Dataset for Story Understanding and Generation]<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2009.02252">KILT: a Benchmark for Knowledge Intensive Language Tasks</a></p>
<h3 id="思考问题："><a href="#思考问题：" class="headerlink" title="思考问题："></a>思考问题：</h3><ul>
<li>以上论文均基于特定数据集，特定场景，给出的特定的测试结果（Metrics），相对的人类用户使用时的感受还有较大的差距。</li>
<li>人工测评的话，成本高、效率低、主观性强。特定用户群很可能产生不同的测评结果。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://willzhuang.github.io/2023/10/11/%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E6%B0%B4%E5%8D%B0%E5%92%8C%E8%AF%86%E5%88%ABAI%E7%94%9F%E6%88%90%E7%9A%84%E5%9B%BE%E5%83%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/11/%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E6%B0%B4%E5%8D%B0%E5%92%8C%E8%AF%86%E5%88%ABAI%E7%94%9F%E6%88%90%E7%9A%84%E5%9B%BE%E5%83%8F/" class="post-title-link" itemprop="url">如何添加水印和识别AI生成的图像</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-11 14:56:00" itemprop="dateCreated datePublished" datetime="2023-10-11T14:56:00+08:00">2023-10-11</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-11-01 16:21:30" itemprop="dateModified" datetime="2023-11-01T16:21:30+08:00">2023-11-01</time>
      </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>人工智能生成的图像每天都变得越来越流行。 但我们如何才能更好地识别它们，尤其是当它们看起来如此逼真时？</p>
<h3 id="1-SynthID"><a href="#1-SynthID" class="headerlink" title="1. SynthID"></a>1. SynthID</h3><p>产品介绍 - <a target="_blank" rel="noopener" href="https://www.deepmind.com/synthid">https://www.deepmind.com/synthid</a><br>产品博客 - <a target="_blank" rel="noopener" href="https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid">https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid</a><br>SynthID 正在使用 <a target="_blank" rel="noopener" href="https://imagen.research.google/">Imagen</a> 向 <a target="_blank" rel="noopener" href="https://cloud.google.com/vertex-ai">Vertex AI</a> 客户发布，<a target="_blank" rel="noopener" href="https://imagen.research.google/">Imagen</a> 是GCP最新的文本到图像模型之一，使用输入文本创建逼真的图像。<br>通过这个工具，用户可以将难以察觉的数字水印嵌入到人工智能生成的图像中，并识别 Imagen 是否用于生成图像，甚至是图像的一部分。<br>SynthID 由 Google DeepMind 开发，并与 Google Research 合作完善。SynthID 并不能万无一失地抵御极端图像处理，但它确实提供了一种有前途的技术方法，使人们和组织能够负责任地使用人工智能生成的内容。该工具还可以与音频、视频和文本等图像之外的其他人工智能模型和模式一起发展。<br>传统水印不足以识别人工智能生成的图像，因为它们通常像图像上的图章一样应用，并且很容易被编辑掉。例如，可以使用基本编辑技术剪掉图像角落中发现的离散水印。<br>在图像处理的不可察觉性和鲁棒性之间找到适当的平衡是很困难的。高度可见的水印通常作为带有名称或徽标的图层添加在图像顶部，也给创意或商业目的带来了审美挑战。同样，一些以前开发的难以察觉的水印可能会通过简单的编辑技术（例如调整大小）丢失。<br>SynthID 不会影响图像质量，并且即使在添加滤镜、更改颜色以及使用各种有损压缩方案（最常用于 JPEG）进行保存等修改之后，水印仍可被检测到。<br>SynthID 使用两种深度学习模型（用于水印和识别），这两种模型已在不同的图像集上一起进行训练。 组合模型针对一系列目标进行了优化，包括正确识别带水印的内容以及通过在视觉上将水印与原始内容对齐来提高不可察觉性。<br>SynthID 允许 Vertex AI 客户负责任地创建 AI 生成的图像并自信地识别它们。 虽然这项技术并不完美，但我们的内部测试表明它对于许多常见的图像处理来说是准确的。</p>
<ul>
<li>SynthID的组合方法：<br>水印：SynthID 可以为 Imagen 生成的合成图像添加难以察觉的水印。‍<br>识别：通过扫描图像中的数字水印，SynthID 可以评估 Imagen 创建图像的可能性。<br>但是该软件没有开源，也没有具体实现原理的介绍。其原理可能与 Stable Signature 一致，请继续阅读下文。</li>
</ul>
<h3 id="2-Stable-Signature"><a href="#2-Stable-Signature" class="headerlink" title="2. Stable Signature"></a>2. Stable Signature</h3><p>开源代码 - <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/stable_signature">https://github.com/facebookresearch/stable_signature</a><br>项目论文 - <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.15435">https://arxiv.org/abs/2303.15435</a><br>Official implementation of the paper “The Stable Signature Rooting Watermarks in Latent Diffusion Models”。在本论文中，作者提出了一种稳定签名的策略，该策略结合了图像水印和潜在扩散模型，以确保生成图像建模的负责任部署。该方法可以快速微调图像生成器的潜在解码器，以在所有生成的图像中隐藏一个不可见的水印，以供未来检测和识别。<br>实现的能力和 SynthID 项目的描述是一样一样的。<br>具体实现方法大体有下面<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.15435">3个步骤（取于论文）</a>：<br><img src="/2023/10/11/%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E6%B0%B4%E5%8D%B0%E5%92%8C%E8%AF%86%E5%88%ABAI%E7%94%9F%E6%88%90%E7%9A%84%E5%9B%BE%E5%83%8F/1.png"></p>
<h3 id="思考问题："><a href="#思考问题：" class="headerlink" title="思考问题："></a>思考问题：</h3><ul>
<li>如果 hacker 通过拷贝屏幕的方式复制图片，如何能够防止，杜绝，或者得到惩罚呢？</li>
<li>经过加密的图片，质量会发生些微的损失。如 Stable Signature 论文所讲，根据经验，在不影响图像质量的情况下，显着降低位精度是很困难的：在纯化过程中开始出现伪影。如何保护图片质量，也是进一步的问题。<a target="_blank" rel="noopener" href="https://www.chatpdf.com/">chatPDF回答</a>：在本论文中，作者提出了一种权衡图像质量和水印鲁棒性的方法，可以通过调整感知损失的权重来实现。较高的感知损失权重会导致更接近原始图像的图像，但提取的水印的位准确性会降低。因此，可以根据具体需求来选择权衡图像质量和水印鲁棒性的方法。</li>
<li>实验和方法的成本很高，尽管比其他计算机视觉领域要低几个数量级。 我们粗略估计用于运行所有实验的总 GPU 天数为 2000，即 ≈ 50000 GPU 小时。 这相当于 10 吨二氧化碳当量的总排放量。</li>
<li>如此方法，引申至3D模型，动画，视频，是否可以重用，目前看还需要思考。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://willzhuang.github.io/2023/09/18/%E5%B9%82%E7%AD%89%E6%80%A7%E6%9C%8D%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/09/18/%E5%B9%82%E7%AD%89%E6%80%A7%E6%9C%8D%E5%8A%A1/" class="post-title-link" itemprop="url">幂等性服务</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-09-18 10:45:00 / Modified: 15:16:02" itemprop="dateCreated datePublished" datetime="2023-09-18T10:45:00+08:00">2023-09-18</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>由于供应商系统的幂等性服务有bug，经过一番争执，终于说服了对方。现将经由记录如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">┌─────────┐      ┌────────────┐     ┌────────────┐</span><br><span class="line">│  客户端  │  ┌──►│  幂等性服务 │  ┌──►│  数据存储   │</span><br><span class="line">└─────────┘  │   └────────────┘  │  └────────────┘</span><br><span class="line">             │                   │</span><br><span class="line">             │                   │</span><br><span class="line">             │   ┌───────────┐   │</span><br><span class="line">             ├──►│ 请求处理   │───┤</span><br><span class="line">             │   └───────────┘   │</span><br><span class="line">             │                   │</span><br><span class="line">             │                   │</span><br><span class="line">             │   ┌───────────┐   │</span><br><span class="line">             ├──►│  检查状态  │───┤</span><br><span class="line">             │   └───────────┘   │</span><br><span class="line">             │                   │</span><br><span class="line">             │                   │</span><br><span class="line">             │   ┌───────────┐   │</span><br><span class="line">             ├──►│ 执行操作   │───┤</span><br><span class="line">             │   └───────────┘   │</span><br><span class="line">             │                   │</span><br><span class="line">             │                   │</span><br><span class="line">             │   ┌───────────┐   │</span><br><span class="line">             ├──►│ 更新状态   │───┤</span><br><span class="line">             │   └───────────┘   │</span><br><span class="line">             │                   │</span><br><span class="line">             └───────────────────┘</span><br></pre></td></tr></table></figure>

<ol>
<li><strong>客户端：</strong> 这是发起请求的外部实体，可能是用户、其他服务或应用程序。</li>
<li><strong>幂等性服务：</strong> 这是幂等性服务的核心组件，负责接收和处理来自客户端的请求。</li>
<li><strong>数据存储：</strong> 数据存储组件用于存储已处理请求的唯一标识符，以及可能需要的其他相关数据。这可以是数据库、缓存或文件系统等。</li>
<li><strong>请求处理：</strong> 请求处理模块负责解析和验证请求，包括提取唯一标识符和其他请求参数。</li>
<li><strong>检查状态：</strong> 在处理请求之前，服务会检查请求的状态，以确保请求之前未被处理过。这一步骤通常涉及检查唯一标识符是否在数据存储中存在。</li>
<li><strong>执行操作：</strong> 执行操作模块负责实际执行请求所需的操作。这可能包括创建订单、更新资源、执行业务逻辑等。</li>
<li><strong>更新状态：</strong> 更新状态模块负责在请求处理成功后，将请求的唯一标识符添加到数据存储中，以标记该请求已被处理。</li>
</ol>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;net/http&quot;</span></span><br><span class="line">    <span class="string">&quot;sync&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 数据存储：使用映射来存储已处理请求的唯一标识符</span></span><br><span class="line"><span class="keyword">var</span> processedRequests = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">bool</span>)</span><br><span class="line"><span class="keyword">var</span> mutex = &amp;sync.Mutex&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 处理HTTP请求的处理程序函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handleRequest</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 从请求中获取唯一标识符</span></span><br><span class="line">    requestID := r.Header.Get(<span class="string">&quot;Request-ID&quot;</span>)</span><br><span class="line">    <span class="comment">// 使用互斥锁保护共享数据</span></span><br><span class="line">    mutex.Lock()</span><br><span class="line">    <span class="keyword">defer</span> mutex.Unlock()</span><br><span class="line">    <span class="comment">// 检查请求是否已经处理过</span></span><br><span class="line">    <span class="keyword">if</span> processedRequests[requestID] &#123;</span><br><span class="line">        <span class="comment">// 如果已处理过，返回已处理的响应</span></span><br><span class="line">        w.WriteHeader(http.StatusOK)</span><br><span class="line">        fmt.Fprintf(w, <span class="string">&quot;Request already processed\n&quot;</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 如果未处理过，执行请求操作</span></span><br><span class="line">        <span class="comment">// 注意：在实际应用中，要确保请求操作是幂等的</span></span><br><span class="line">        result := performRequestOperation(r)</span><br><span class="line">        <span class="comment">// 更新已处理请求的映射</span></span><br><span class="line">        processedRequests[requestID] = <span class="literal">true</span></span><br><span class="line">        <span class="comment">// 返回操作结果</span></span><br><span class="line">        <span class="keyword">if</span> result &#123;</span><br><span class="line">            w.WriteHeader(http.StatusOK)</span><br><span class="line">            fmt.Fprintf(w, <span class="string">&quot;Request processed successfully\n&quot;</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            w.WriteHeader(http.StatusInternalServerError)</span><br><span class="line">            fmt.Fprintf(w, <span class="string">&quot;Request processing failed\n&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行请求操作的函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">performRequestOperation</span><span class="params">(r *http.Request)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">    <span class="comment">// 在这里执行实际的请求操作，确保操作是幂等的</span></span><br><span class="line">    <span class="comment">// 例如，创建订单、更新资源、执行业务逻辑等</span></span><br><span class="line">    <span class="comment">// 如果操作成功，返回true；否则返回false</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// 创建HTTP服务器</span></span><br><span class="line">    http.HandleFunc(<span class="string">&quot;/process&quot;</span>, handleRequest)</span><br><span class="line">    http.ListenAndServe(<span class="string">&quot;:8080&quot;</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Bug针对上述代码中的 <code>result</code> ，如果是 false 的情况下，该 Token 的请求处理结果应该记录为 <code>false</code>， 即 <code>processedRequests[requestID] = false</code>。<br>本例子中，供应商的错误在哪里呢？供应商系统的幂等服务，在24小时内，如果出现错误，服务不会重新执行，而是认为已经处理完成，继续抛出同样的 error message。实在不能够接受。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://willzhuang.github.io/2023/09/14/BloombergGPT%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/09/14/BloombergGPT%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" class="post-title-link" itemprop="url">BloombergGPT论文解读</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-09-14 16:31:00 / Modified: 17:13:31" itemprop="dateCreated datePublished" datetime="2023-09-14T16:31:00+08:00">2023-09-14</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h3><p>BloombergGPT是布隆伯格2023年3月30日公开在arXiv的一篇文章——<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.17564">BloombergGPT: A Large Language Model for Finance</a>中涉及到的语言模型，也是金融领域第一个公开发表文章的大语言模型（以下简称“LLM”）。</p>
<h3 id="2-要点"><a href="#2-要点" class="headerlink" title="2. 要点"></a>2. 要点</h3><ul>
<li>BloombergGPT是Bloomberg训练出来的金融大语言模型（LLM for Finance）</li>
<li>模型参数量为500亿，使用了包含3630亿token的金融领域数据集以及3450亿token的通用数据集</li>
<li>隐藏层维度为7680，多头的头数为40</li>
<li>模型采用Unigram tokenizer，AdamW优化器</li>
<li>模型在64个AWS的p4d.24xlarge实例上训练了53天，其中每个p4d.24xlarge实例包含了8块40GB的A100GPU</li>
<li>对BloombergGPT的评估包含了两部分：金融领域评估与通用领域评估</li>
<li>评估对比的其他大语言模型有GPT-NeoX、OPT、BLOOM、GPT-3</li>
<li>在金融领域任务上，BloombergGPT综合表现最好；在通用任务上，BloombergGPT的综合得分同样优于相同参数量级的其他模型，并且在某些任务上的得分要高于参数量更大的模型</li>
<li>BloombergGPT模型在金融领域取得好效果的同时，并没有以牺牲模型通用能力为代价</li>
<li>对模型定性评估的结果表明，BloombergGPT可以提高工作效率</li>
<li>出于安全性的考虑，BloogbergGPT模型不会被公开，但是模型训练和评估的相关经验和思考会被分享出来</li>
<li>作者认为，对模型效果提升促进最大的三个因素（按影响从高到低排序）分别为精心清洗的数据集、合理的tokenizer、流行的模型结构</li>
</ul>
<p>文章的主要贡献在以下几点：</p>
<ul>
<li>混合数据集训练方法不仅可以在特定任务上表现出色，也可以在一般NLP基准测试上表现良好</li>
<li>不同于常见的网络爬取数据，本文的数据包含了巨量的可信来源的精心清洗的数据</li>
<li>不仅包含了模型在基准测试集上的评估结果，也包含了在Bloomberg内部任务上的评估结果</li>
<li>在超过7000亿个token的语料库中的5690亿个token上训练出一个500亿参数的LLM</li>
<li>使用Unigram模型而非常用的基于贪心合并的子词标记器进行tokenize，方便在推理时进行更智能的标记化</li>
<li>借鉴BLOOM的训练大模型方法，同时也将自己自己在训练BloombergGPT中的经验分享</li>
</ul>
<h3 id="3-数据集"><a href="#3-数据集" class="headerlink" title="3.数据集"></a>3.数据集</h3><p><strong>BloombergGPT是一个有500亿参数、基于BLOOM模型的LLM</strong>，过程中采用了一种兼具通用能力和特定领域的方法。<br>作者首先构建了FinPile——一个包含了新闻、档案、网络爬取的新闻稿件、英文财经文档等英文金融文档的金融领域数据集，同时也采用了通用的数据集。</p>
<h4 id="金融领域数据集"><a href="#金融领域数据集" class="headerlink" title="金融领域数据集"></a>金融领域数据集</h4><p>金融领域数据集共包含了3630亿个token，占总数据集token量的54.2%，具体由以下几个部分构成：</p>
<ul>
<li>金融领域相关网页，2980亿token，占比42.01%</li>
<li>金融领域知名新闻源，380亿token，占比5.31%</li>
<li>公司财报，140亿token，占比2.04%</li>
<li>金融相关公司的出版物，90亿token，占比1.21%</li>
<li>bloomberg，50亿token，占比0.7%</li>
</ul>
<p>因为包含一部分收费和私有数据，所以这份数据集不会被公开，但是文章中公开了模型训练方法。</p>
<h4 id="通用数据集"><a href="#通用数据集" class="headerlink" title="通用数据集"></a>通用数据集</h4><p>**通用数据集共包含了3450亿个token，占总数据集token量的48.73%**，具体分为如下几个部分：</p>
<ul>
<li>The Pile数据集，1840亿token，占比25.9%</li>
<li>C4数据集，1380亿token，占比19.48%</li>
<li>Wikipedia数据集，240亿token，占比3.35%</li>
</ul>
<p>数据集使用Unigram tokenizer对原始文本进行tokenize。具体处理时，作者这了两点改进（具体内容可参考原论文《2.3Tokenization》）：</p>
<ul>
<li>在pretokenization这一步，将数字视为单个token，并且允许词组的存在，以提高信息密度减少句子长度</li>
<li>使用分治的思想优化Unigram tokenizer在大数据集上的实现，并对最终词表大小控制在13万这个数量级上</li>
</ul>
<h3 id="4-模型"><a href="#4-模型" class="headerlink" title="4.模型"></a>4.模型</h3><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>模型基于BLOOM模型的自回归结构，具体包含了70层transformer decoder。<br>另外一些细节如下（详见《3.1 Architecture》）：</p>
<ul>
<li>前馈层（FFN）中的非线性函数采用GELU</li>
<li>位置编码采用ALiBi编码</li>
<li>模型在第一层多了一个layer normalization</li>
</ul>
<h4 id="模型尺度"><a href="#模型尺度" class="headerlink" title="模型尺度"></a>模型尺度</h4><p>这一部分，作者先有了算力预算（<strong>40G内存A100共130万GPU小时</strong>），并且给中间checkpoint存储留出了约25%的时间预算。<br><strong>根据Chinchilla scaling laws，计算出模型的参数和需要的数据量大小——模型参数为500亿，token数据量为11000+亿</strong>。<br>考虑到金融领域token数量要占总token数量的50%以上，而且目前的数据暂时无法再进行扩充，最终<strong>模型参数量选择为500亿，token数据量为7000+亿</strong>。<br>另一方面，隐藏层维度D也可以根据decoder的层数计算出来，这里经过计算<strong>隐藏层维度为7680</strong>，多头的<strong>头数为40</strong>。</p>
<h4 id="训练配置"><a href="#训练配置" class="headerlink" title="训练配置"></a>训练配置</h4><p>这一部分原始论文写的比较详细，具体见《3.3 Training Configuration》，这里简单摘要如下：</p>
<ul>
<li>作者在<strong>每篇文档的最后添加了特殊标记&lt;|endoftext|&gt;，模型训练时选取的句子长度为2048token</strong></li>
<li>训练时采用的优化方法是<strong>AdamW，beta1、beta2、weight decay取值分别为0.9、0.95、0.1</strong>，初始学习率为6e-5，采用cosine衰减、线性warmup方式</li>
<li>模型参数随机初始化为<strong>均值0、标准差0.006588的正态分布</strong>，并对MLP的第二层和注意力层输出进行缩放</li>
<li>关于训练的不稳定性，文章中没有描述训练BloombergGPT时采用的方法，只是介绍了相关进展</li>
<li>关于计算使用到的硬件，使用了<strong>64个AWS的p4d.24xlarge实例，每个p4d.24xlarge实例包含了8块40GB的A100GPU</strong></li>
</ul>
<h4 id="大规模优化采用的方法"><a href="#大规模优化采用的方法" class="headerlink" title="大规模优化采用的方法"></a>大规模优化采用的方法</h4><p>这一部分中，作者描述了具体优化时采用的方法：ZeRO优化、MiCS、Activation Checkpointing、混合精度训练（Mixed Precision Training）、内核融合（fused kernels）。<br>具体见《3.4 Large-scale Optimization》<br>经过上述优化，上述硬件的<strong>平均算力水平达到了102TFLOPs</strong>，<strong>训练一步需要32.5秒</strong>。</p>
<h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><p>文章中记录<strong>模型共训练了139,200步</strong>，进行了约<strong>0.8个epoch</strong>，<strong>训练了53天</strong>。<br>一个epoch都没有训练完的原因是这时验证集上的损失函数已经不再继续下降了。<br><strong>具体训练过程如下</strong>：</p>
<ul>
<li>初始训练的batch size大小为1024，warm-up过程持续了7200步，随后作者将batch size修改为2048。</li>
<li>115,500步之后，验证集上的损失不再下降，然后作者将学习率缩小为原始的2/3；</li>
<li>129,900步之后，学习率缩小为之前的1/2，同时增加dropout</li>
<li>137,100步之后，学习率再次缩小为之前的1/2</li>
<li>最终，训练在146,000步结束。作者选取139,200这一步的模型最为最终使用的模型</li>
</ul>
<p>这里推荐阅读原始文章3.3节与3.4节中关于训练方法的描述，对于大模型训练有一定的参考意义。</p>
<h3 id="5-评估"><a href="#5-评估" class="headerlink" title="5.评估"></a>5.评估</h3><p>文章中对BloombergGPT的<strong>评估分成了两部分</strong>：<strong>金融领域任务与通用任务</strong>。这样做的目的也比较直观，就是<strong>验证在特定领域预训练后的模型能够在特定领域表现好，同时在通用领域的表现也不会差太多</strong>这一观点。<br>同时，文章<strong>对比了BloombergGPT、GPT-NeoX、OPT、BLOOM、GPT-3在不同任务上的表现</strong>。注意，这里<strong>因为GPT-3模型无法获取，故仅在部分通用任务上进行了评测</strong>。<br>作者对每一个模型均独立进行了评测，并且在每一个任务中使用相同的标准prompt、相同的样例、不使用任务描述和任何CoT prompt，以保证评测结果的公平性。<br>对于有多个答案的任务，文章中采用了**基于似然的分类方法（likelihood-based classification）进行评估；对于其他任务，文章采用贪心解码（greedy decoding）的方式进行评估。</p>
<h4 id="holdout-loss"><a href="#holdout-loss" class="headerlink" title="holdout loss"></a>holdout loss</h4><p>作者首先在FinPile数据集预留的部分样本上对各个模型进行了bits per byte的评估。<br>bits per byte指标是评估语言模型的一种常见指标<strong>，类似于perplexity，取值越小，模型越好。具体计算方法可见</strong><a target="_blank" rel="noopener" href="https://stats.stackexchange.com/a/261789">How to compute bits per character (BPC)?</a><br><strong>BloombergGPT在金融语料上的bits per byte均好于其他模型，并且在财报（Filings）这个类别上表现尤其突出</strong>。这个结果也符合预期。否则可能就没有后面任务对比的必要了。<br>文章又将金融领域任务分成了<strong>外部任务和Bloomberg内部任务</strong>。在每个任务上，作者除了评估模型在任务上的表现，还评估了同一任务下不同模型生成结果之间两两比较的胜率（WR）。</p>
<h4 id="外部任务"><a href="#外部任务" class="headerlink" title="外部任务"></a>外部任务</h4><p>外部任务主要如下：</p>
<ul>
<li>ConvFinQA，标普500收益报告问答推理</li>
<li>FiQA SA，金融新闻和微博客标题基于方面的情感三分类（正负中）</li>
<li>FPB，金融新闻句子级别情感三分类（正负中）</li>
<li>Headline，新闻标题在预定义标签下的二分类</li>
<li>NER，信用风险评估数据的命名实体识别</li>
</ul>
<p><strong>BloombergGPT在上述5个任务中的4个都取得了最好效果，在另外一个取得了第二名；并且在模型两两结果对比的胜率最高，同时在ConvFinQA这个任务上遥遥领先。</strong></p>
<h4 id="Bloomberg内部任务之情感分析"><a href="#Bloomberg内部任务之情感分析" class="headerlink" title="Bloomberg内部任务之情感分析"></a>Bloomberg内部任务之情感分析</h4><p>这个任务中的情感分析均为基于方面的情感三分类（aspect-specific sentiment），数据集的内容通过任务名称就可以略知一二。<br><strong>BloombergGPT在上述4个数据集上的表现均大幅领先于其他模型</strong>。</p>
<h4 id="探索性任务：NER"><a href="#探索性任务：NER" class="headerlink" title="探索性任务：NER"></a>探索性任务：NER</h4><p>注意，这里的<strong>NER只涉及到ORG、PER、LOC这三类实体</strong>。<br>同时探索性任务<strong>NER+NED是指识别出实体后再将实体链接到上市公司的股票简称</strong>。比如“AAPL announced that they will stop using Intel chips in future products.” 这句话<strong>NER的结果是“AAPL, Intel”</strong>，<strong>NER+NED的结果是 “AAPL, INTC”</strong>。<br>这两类任务涉及到的数据集包括了<strong>7个数据集</strong>，分别为BN（Bloomberg BN wire上内容）、BFW（Bloomberg First Word上的内容）、Filings（财报内容）、Headlines（Bloomberg news内容）、Premium（Bloogberg收录 的第三方新闻内容）、Transcripts（公司新闻发布会的文字记录）、Social Media。<br>最终，<strong>NER任务下，BloombergGPT仅在Headlines这一个数据集上得分最高；但在NER+NED任务下，BloombergGPT在除了Social Media任务的其他任务上均得分第一</strong>。</p>
<h4 id="通用任务"><a href="#通用任务" class="headerlink" title="通用任务"></a>通用任务</h4><p>文章在通用任务上做了相当多的对比，这里<strong>仅对任务类型和结果做简要描述，详细内容见文章中的5.4~5.7节</strong>。<br>作者在<strong>BIG-bench Hard</strong>（BIG-bench的一个子集，仅包含目前模型表现无法超过人类的任务）、<strong>常识测试</strong>（不提供任何背景知识，仅可以训练时使用的数据）、<strong>阅读理解</strong>、<strong>语言学</strong>（消歧、语法识别、蕴含判别等）等任务上进行了测试。<br><strong>在BIG-bench Hard任务上，BloombergGPT得分低于参数量更大的PaLM和BLOOM，但是与参数规模类似的GPT-NeoX或OPT66B相比，BloombergGPT的性能更接近BLOOM</strong>，这说明开发金融专用的大语言模型并没有明显牺牲其通用能力。<br><strong>在常识测试任务中，BloombergGPT在1个任务上取得了第一名，在其余3个任务上取得了第二名（这里未考虑GPT-3）</strong>。<br><strong>在阅读理解任务上，GPT-3在所有任务上排名第一，BloombergGPT在5/6个任务上排名第二</strong>，且得分远高于BLOOM模型。<br><strong>在语言学任务上，GPT-3在综合排名第一，BloombergGPT综合排名第二</strong>，且综合得分高于BLOOM模型。</p>
<h4 id="评测总结"><a href="#评测总结" class="headerlink" title="评测总结"></a>评测总结</h4><p><strong>在金融领域任务上，BloombergGPT综合表现最好</strong>；<br><strong>在通用任务上，BloombergGPT的综合得分优于相同参数量级的其他模型，并且在某些任务上的得分要高于参数量更大的模型</strong>。<br>这都说明，开发金融专用的大语言模型在金融领域取得好效果的同时，并没有以牺牲模型通用能力为代价。<br>这一结论也可以给我们一个启示，<strong>在其他特定领域，我们也可以开发专用的大语言模型</strong>。</p>
<h4 id="定性评估"><a href="#定性评估" class="headerlink" title="定性评估"></a>定性评估</h4><p>作者在文章的第6章还展示了对BloombergGPT定性评估的例子，以展示模型在专业领域带来的促进作用。<br>这些列子包括：</p>
<ul>
<li>BQL（Bloomberg查询语言）生成，即使用自然语言完成Bloomberg数据库查询，类似NL2SQL</li>
<li>新闻标题提示，辅助记者生成新闻短标题</li>
<li>金融问答</li>
</ul>
<h3 id="6-道德伦理、限制与研究意义"><a href="#6-道德伦理、限制与研究意义" class="headerlink" title="6.道德伦理、限制与研究意义"></a>6.道德伦理、限制与研究意义</h3><p>这一章没有太多值得写的，主要就是强调了目前大语言模型可能会生成有害的、有偏见的内容，并且可能存在prompt注入导致信息泄露的风险，Bloomberg在使用大语言模型前后都会做好风控，保证生成内容的准确性。<br>同时，<strong>BloogbergGPT模型不会被公开，但是模型训练和评估的相关经验和思考会被分享出来</strong>。</p>
<h3 id="7-总结与展望"><a href="#7-总结与展望" class="headerlink" title="7.总结与展望"></a>7.总结与展望</h3><p>文章提出了BloombergGPT——一个金融领域顶级的LLM，并且在训练特定领域大语言模型做出了如下贡献：</p>
<ul>
<li><strong>使用领域数据和通用数据的训练方式可以让模型在这两个方面得到平衡的结果</strong></li>
<li>模型参数量参考了Chinchilla scaling laws</li>
<li>公布了相关训练细节</li>
</ul>
<p>下一步，作者们会在以下方向继续研究：</p>
<ul>
<li>金融领域的fine-tuning</li>
<li>使用更无害和更无偏见的语言</li>
<li>研究tokenization方法对模型结果的影响</li>
</ul>
<p>最后，作者把模型取得目前效果归结于以下三个因素（按影响从高到低排序）：</p>
<ul>
<li><strong>精心清洗的内部数据集</strong></li>
<li><strong>tokenizer的选择</strong></li>
<li><strong>流行的模型结构</strong></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://willzhuang.github.io/2023/09/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Weiming Zhuang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhuang's Diary">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/09/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">深度学习推荐模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-09-14 13:49:00 / Modified: 14:25:48" itemprop="dateCreated datePublished" datetime="2023-09-14T13:49:00+08:00">2023-09-14</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><img src="/2023/09/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B/1.jpg"></p>
<ol>
<li><p>改变神经网络的复杂程度: 从最简单的单层神经网络模型 AutoRec ( 自编码器推荐)，到经典的深度神经网络结构 Deep Crossing(深度特征交叉)，其主 要的进化方式在于 增加了深度神经网络的层数和结构复杂度。</p>
</li>
<li><p>改变特征交叉方式: 这类模型的主要改变在于丰富了深度学习网络中特征交叉的方式。例如，改变了用户向量和物品向量互操作方式的 NeUralCF( Neural Collaborative Filtering,神经网络协同过滤)，定义了多种特征向量交叉操作的 PNN ( Product-based Neural Network, 基于积操作的神经网络 )模型。</p>
</li>
<li><p>组合模型: 这类模型主要是指 Wide&amp;Deep 模型及其后续变种 Deep&amp;Cross,DeepFM等，其思路是通过组合两种不同特点、优势互补的深度学 习网络，提升模型的综合能力。</p>
</li>
<li><p>FM 模型的深度学习演化版本: 传统推荐模型 FM 在深度学习时代有了 诸多后续版本，其中包括 NFM ( Neural Factorization Machine, 神经网络因子分解机 )、FNN ( Factorization-machine supported Neural Network, 基于因子分解机支持的神经网络)、AFM(Attention neural Factorization Machine, 注意力因子分解机)等，它们对 FM 的改进方向各不相同。例如，NFM 主要使用神经网络提升 FM 二阶部分的特征交叉能力，AFM 是引入了注意力机制的 FM 模型，FNN 利用 FM 的结果进行网络初始化。</p>
</li>
<li><p>注意力机制与推荐模型的结合: 这类模型主要是将“注意力机制”应用于深度学习推荐模型中，主要包括结合了 FM 与注意力机制的 AFM 和引入了注 意力机制的 CTR 预估模型 DIN ( Deep Interest Network, 深度兴趣网络)。</p>
</li>
<li><p>序列模型与推荐模型的结合: 这类模型的特点是使用序列模型模拟用户行为或用户兴趣的演化趋势，代表模型是 DIEN( Deep Interest Evolution Network, 深度兴趣进化网络 )。</p>
</li>
<li><p>强化学习与推荐模型的结合: 这类模型将强化学习应用于推荐领域，强调模型的在线学习和实时更新，其代表模型是 DRN( Deep Reinforcement Learning Network, 深度强化学习网络 )。</p>
</li>
</ol>
<p>— 摘录于《深度学习推荐模型》</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/47/">47</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>


<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Weiming Zhuang</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'none'
      },
      options: {
        renderActions: {
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>




</body>
</html>
